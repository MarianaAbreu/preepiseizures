{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/saraiva/dev/Respiration/APNEIA/T05_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_7_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_7_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_7_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_1_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_6_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_7_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_8_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_8_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_8_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_8_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T01_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T05_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T03_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_2_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_4_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T04_5_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T02_3_BITALINO.csv', '/Users/saraiva/dev/Respiration/APNEIA/T06_8_BITALINO.csv']\n"
     ]
    }
   ],
   "source": [
    "# built-in modules\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import string   \n",
    "\n",
    "# third-party modules\n",
    "import biosppy as bp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from scipy import signal\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# local modules\n",
    "import multiAE_creation as mc\n",
    "from utils_classification import fus_classifier\n",
    "\n",
    "# files names\n",
    "bitalino = \"/Users/saraiva/dev/Respiration/APNEIA/\"\n",
    "# all_files = [folder+ol for ol in os.listdir(folder)]\n",
    "bitalino_files = [bitalino + ol for ol in os.listdir(bitalino)]\n",
    "print(bitalino_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load labels\n",
    "\n",
    "all_ap will contain the labels of the 70 subjects, while resp_ap will contain the labels of the 8 subjects which have both ecg and resp signals\n",
    "\n",
    "pd_all and pd_resp show the number of apnea and normal samples for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def normal(sg, minsg, maxsg):\n",
    "    res = 100 * (sg - minsg) / (maxsg - minsg)\n",
    "    return res\n",
    "\n",
    "def find_extremes(sig, mode, th):\n",
    "    indexes, values = bp.tools.find_extrema(sig, mode)\n",
    "    ind, peaks = [], []\n",
    "    for pk in range(len(values)):\n",
    "        if abs(values[pk] - np.mean(sig)) > float(th):\n",
    "            ind += [indexes[pk]]\n",
    "            peaks += [values[pk]]\n",
    "    return ind, peaks\n",
    "\n",
    "\n",
    "def deep_breath(sig):\n",
    "    #the signal of the first apnea is received. The deep breath is characterized by a\n",
    "    #sudden increase, which corresponds to a high value of the positive derivative.\n",
    "    #to find the deep breathe we use find extremes\n",
    "    ind, peaks = find_extremes(sig, 'both', 0.3)\n",
    "    if peaks == []:\n",
    "        plt.plot(sig)\n",
    "        plt.scatter(ind,peaks)\n",
    "        plt.show()\n",
    "    div1 = np.diff(peaks)\n",
    "    deep_b = np.max(div1)\n",
    "    if deep_b > 0:\n",
    "        print('\\ndeep breathe was found')\n",
    "        deep_idx = int(np.where(div1 == deep_b)[0])\n",
    "        res = [peaks[deep_idx], peaks[deep_idx+1]]\n",
    "    else:\n",
    "        print(peaks, div1)\n",
    "        res = 0\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "marker_label = dict([(2, 'N'), (5, 'N'), (8, 'A'), (10, 'A'), (12, 'A'), (14, 'A'), (16, 'A')])\n",
    "_label = dict([(0, 'N'), (1, 'N'), (2, 'A'), (3, 'A'), (4, 'A'), (5, 'A'), (6, 'A')])\n",
    "\n",
    "sb.set(font_scale=3)\n",
    "user_labs = []\n",
    "user_data = []\n",
    "for bf in range(len(bitalino_files)):\n",
    "    labs = []\n",
    "    data = []\n",
    "    df = pd.read_csv(bitalino_files[bf], parse_dates=True, index_col=0, header=0,sep=';')\n",
    "\n",
    "    resp = np.array(bp.tools.filter_signal(df.A1, ftype='butter', band='bandpass', order=2, frequency=[0.01,0.35],sampling_rate=1000.)[\n",
    "                        'signal'])\n",
    "    resp = normal(resp,np.min(resp),np.max(resp))\n",
    "    list_markers = [[mk, marker] for mk, marker in enumerate(df.MARKER) if\n",
    "                        marker != 0 and marker in marker_label.keys()]\n",
    "\n",
    "    print(list_markers)\n",
    "    arr = np.array(list_markers)[:,0]*0.001\n",
    "    la = 0\n",
    "    for o, lm in enumerate(arr[::2]):\n",
    "        print(o, lm)\n",
    "        init = list_markers[o*2][0]\n",
    "        end = list_markers[o*2+1][0]\n",
    "        if _label[la] == 'A':\n",
    "            x_arr = np.arange(init*0.001,end*0.001, 0.001)\n",
    "            if len(np.arange(init*0.001,end*0.001, 0.001)) != len(resp[init:end]):\n",
    "                x_arr = x_arr[:-1]\n",
    "        la+=1\n",
    "\n",
    "\n",
    "    deep = resp[list_markers[4][0]:list_markers[5][0]]\n",
    "    xminmax = deep_breath(deep)\n",
    "\n",
    "    for lm in range(0,len(list_markers),2):\n",
    "        sig = resp[list_markers[lm][0]:list_markers[lm+1][0]]\n",
    "        lab = marker_label[list_markers[lm][1]]\n",
    "        \n",
    "        for k in range(0,len(sig)-60000,60000):\n",
    "            signl = sig[k:k+59999]\n",
    "            signl = signal.resample(normal(signl, np.min(signl), np.max(signl)),1000)\n",
    "            labs += [lab]\n",
    "            data += [signl]\n",
    "\n",
    "    user_labs += [labs]\n",
    "    user_data += [data]\n",
    "            \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"user_labs\", \"wb\") as output_file:\n",
    "    pickle.dump(user_labs, output_file)\n",
    "\n",
    "with open(r\"user_data\", \"wb\") as output_file:\n",
    "    pickle.dump(user_data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _UR = data_resp\n",
    "#_ap = pickle.load(open('RespN_Y','rb'))\n",
    "_UR = user_data\n",
    "_ap = user_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def part_balance(list_vecs, list_lab):\n",
    "    train = []\n",
    "    lab = []\n",
    "    for v, vec in enumerate(list_vecs):\n",
    "\n",
    "        num = list_lab[v].count('A')\n",
    "        if num != 0:\n",
    "            sel = random.choices(vec[:-num], k=num)\n",
    "            tr = np.concatenate([sel, vec[-num:]])\n",
    "            ba = ['N']*num + ['A']*num\n",
    "\n",
    "            train += [tr]\n",
    "            lab += [ba]\n",
    "\n",
    "            if len(tr)!=len(ba):\n",
    "                aaaa\n",
    "    return train, lab\n",
    "\n",
    "def create_autoencoder(x_train,y_train, x_test, y_test, label, loss, \n",
    "                       activ = 'tanh', opt = 'adam', nodes = [500,250,50],epochs=100):\n",
    "    mc.autoencoder_params(nodes[-1], 1000, nodes, activ, opt,  loss,\n",
    "                          x_train,y_train, x_test, y_test,label, epochs)\n",
    "\n",
    "def separate_classes(vecs,labs, classes=['A','N']):\n",
    "    #take the whole set and separate classes.\n",
    "    new_vec, new_labs = [],[]\n",
    "    for cl in classes:\n",
    "        \n",
    "        cl_index = [i for i in range(len(labs)) if labs[i] == cl]\n",
    "        vec_ = np.array(vecs)[cl_index]\n",
    "        lab_ = np.array(labs)[cl_index]\n",
    "        new_vec += [vec_]\n",
    "        new_labs += [lab_]\n",
    "    return new_vec, new_labs\n",
    "\n",
    "# for user in range(len(_UR)):\n",
    "    \n",
    "#     training_set_x = list(_UR)\n",
    "#     del(training_set_x[user])\n",
    "#     training_set_y = _ap[:]\n",
    "#     del(training_set_y[user])\n",
    "#     training_set_x = np.concatenate(training_set_x, axis=0)\n",
    "#     print(np.array(training_set_x).shape)\n",
    "#     training_set_y = np.concatenate(training_set_y)\n",
    "    \n",
    "#     train, y_train = separate_classes(training_set_x, training_set_y)\n",
    "    \n",
    "#     ap_train = train[0]\n",
    "#     n_train = train[1]\n",
    "#     #training_set_y = np.array([1 if yt == 'N' else 0 for yt in training_set_y])\n",
    "    \n",
    "#     ap_train, ap_test, ap_ytrain, ap_ytest = \\\n",
    "#         train_test_split(ap_train, y_train[0], test_size=.4, random_state=42)\n",
    "#     n_train, n_test, n_ytrain, n_ytest = \\\n",
    "#         train_test_split(n_train, y_train[1], test_size=.4, random_state=42)\n",
    "#     #print('This train contains ' + str(list(ae_ytrain).count('A')) + ' Apneas and ' + str(list(ae_ytrain).count('N')) + ' Normal events')\n",
    "    \n",
    "#     loss = 'cosine_proximity'\n",
    "#     activ='tanh'\n",
    "#     opt='adam'\n",
    "    \n",
    "#     nodes = [500,250,50]\n",
    "    \n",
    "    \n",
    "#     create_autoencoder(n_train, n_train, n_test, n_test, 'RN', loss, activ, opt, nodes = nodes, epochs=50)\n",
    "#     #create_autoencoder(n_train, n_train, n_test, n_test, 'RC', loss, activ, opt, nodes = nodes, epochs=50)\n",
    "    \n",
    "#     encoder = pickle.load(open('RN_encoder', 'rb'))\n",
    "#     decoder = pickle.load(open('RN_decoder', 'rb'))\n",
    "    \n",
    "#     testing_set_x = _UR[user]\n",
    "#     testing_set_y = _ap[user]\n",
    "    \n",
    "#     enc = encoder.predict(testing_set_x)\n",
    "#     dec = decoder.predict(enc)\n",
    "    \n",
    "#     for d in range(len(dec)):\n",
    "        \n",
    "#         plt.plot(dec[d], label=testing_set_y[d])\n",
    "#         corr = [pearsonr(dec[d][i:i+100],testing_set_x[d][i:i+100])[0] for i in range(0,len(dec[d]),100)]\n",
    "#         plt.title(corr)\n",
    "#         plt.plot(testing_set_x[d], label='input')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "signal = _UR[:]\n",
    "#all_corr = []\n",
    "for user in range(len(signal)):\n",
    "    \n",
    "    training_set_x = list(signal)\n",
    "    del(training_set_x[user])\n",
    "    training_set_y = _ap[:]\n",
    "    del(training_set_y[user])\n",
    "    training_set_x = np.concatenate(training_set_x, axis=0)\n",
    "    print(np.array(training_set_x).shape)\n",
    "    training_set_y = np.concatenate(training_set_y)\n",
    "    \n",
    "    train, y_train = separate_classes(training_set_x, training_set_y)\n",
    "    \n",
    "    #ap_train = train[0]\n",
    "    #n_train = train[1]\n",
    "    #training_set_y = np.array([1 if yt == 'N' else 0 for yt in training_set_y])\n",
    "    \n",
    "    #ap_train, ap_test, ap_ytrain, ap_ytest = \\\n",
    "     #   train_test_split(ap_train, y_train[0], test_size=.4, random_state=42)\n",
    "    n_train, n_test, n_ytrain, n_ytest = \\\n",
    "        train_test_split(train[1], y_train[1], test_size=.4, random_state=42)\n",
    "    #print('This train contains ' + str(list(ae_ytrain).count('A')) + ' Apneas and ' + str(list(ae_ytrain).count('N')) + ' Normal events')\n",
    "    \n",
    "    loss = 'cosine_similarity'\n",
    "    #loss = 'mean_squared_error'\n",
    "    activ='tanh'\n",
    "    opt='adam'\n",
    "    \n",
    "    nodes = [500,250,50]\n",
    "    \n",
    "    \n",
    "    #create_autoencoder(ap_train, ap_train, ap_test, ap_test, 'RN', loss, activ, opt, nodes = nodes, epochs=50)\n",
    "    create_autoencoder(n_train, n_train, n_test, n_test, 'RN', loss, activ, opt, nodes = nodes, epochs=50)\n",
    "    \n",
    "    encoder = pickle.load(open('RN_encoder', 'rb'))\n",
    "    decoder = pickle.load(open('RN_decoder', 'rb'))\n",
    "    \n",
    "    testing_set_x = np.array(signal[user])\n",
    "    testing_set_y = _ap[user]\n",
    "    \n",
    "    enc = encoder.predict(testing_set_x)\n",
    "    dec = decoder.predict(enc)\n",
    "    save_corr = []\n",
    "    enc_train = encoder.predict(training_set_x)\n",
    "    dec_train = decoder.predict(enc_train)\n",
    "    train_cl,test_cl = [],[]\n",
    "    y_train_new = []\n",
    "    y_test_new = []\n",
    "    for d in range(len(dec_train)):\n",
    "        corr_train = [pearsonr(dec_train[d][i:i+100],training_set_x[d][i:i+100])[0] for i in range(0,len(dec_train[d]),100)]\n",
    "        if np.isfinite(corr_train).all():\n",
    "            train_cl += [corr_train]\n",
    "            y_train_new += [training_set_y[d]]\n",
    "\n",
    "    for d in range(len(dec)):\n",
    "        \n",
    "        plt.plot(dec[d])\n",
    "        corr = [pearsonr(dec[d][i:i+100],testing_set_x[d][i:i+100])[0] for i in range(0,len(dec[d]),100)]\n",
    "        \n",
    "        if np.isfinite(corr).all():\n",
    "            test_cl += [corr]\n",
    "            y_test_new += [testing_set_y[d]]\n",
    "        \n",
    "    cl_score = []\n",
    "    \n",
    "    names = [\"SVM\", \"Random Forest\"] \n",
    "    \n",
    "    classifiers = [SVC(gamma=2, C=1, probability=True),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]\n",
    "    \n",
    "    cl_score = fus_classifier(classifiers, names, train_cl,\\\n",
    "                                  test_cl, np.array(y_train_new), np.array(y_test_new), show=True)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3\n",
      "16.459343850834394\n",
      "83.45454545454545\n",
      "15.173922824513692\n"
     ]
    }
   ],
   "source": [
    "svm = [93,40,67,100,40,100,67,100,80,93,100,100,100,100,87,67,80,73,73,53,\\\n",
    "       100,100,93,80,100,100,100,73,100,100,93,100,87,80,87,93,100,80,73,100]\n",
    "rf = [93,47,67,87,47,100,80,100,67,93,93,93,93,100,93,60,80,73,80,60,100,\\\n",
    "      100,93,80,100,100,100,73,93,93,80,93,87,80,87,87,100,73,60,80,80,93,47,87]\n",
    "\n",
    "print(np.mean(svm))\n",
    "print(np.std(svm))\n",
    "\n",
    "print(np.mean(rf))\n",
    "print(np.std(rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node model_139/dense_276/MatMul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 728, in start\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n\n  File \"/var/folders/jv/_bqrt3cs093f3fmttdr0hpnm0000gn/T/ipykernel_8991/3977339241.py\", line 3, in <module>\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node model_139/dense_276/MatMul}}]] [Op:__inference_predict_function_173094]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m user_data[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     enc \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     dec \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mpredict(enc)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m da \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n",
      "File \u001b[0;32m~/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_139/dense_276/MatMul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 728, in start\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n\n  File \"/var/folders/jv/_bqrt3cs093f3fmttdr0hpnm0000gn/T/ipykernel_8991/3977339241.py\", line 3, in <module>\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/saraiva/dev/PreEpiSeizuresCode/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node model_139/dense_276/MatMul}}]] [Op:__inference_predict_function_173094]"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "for data in user_data[0]:\n",
    "    enc = encoder.predict(data)\n",
    "    dec = decoder.predict(enc)\n",
    "\n",
    "\n",
    "    for da in range(len(data)):\n",
    "        \n",
    "        plt.plot(data[da], label='input')\n",
    "        plt.plot(dec[da], label='output')\n",
    "        corr = pearsonr(data[da],dec[da])\n",
    "\n",
    "        plt.title(str(corr))\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# names = [\"Decision Tree\", \"AdaBoost\",\"GradBoost\"]\n",
    "\n",
    "# classifiers = [DecisionTreeClassifier(max_depth=5),\n",
    "#     AdaBoostClassifier(),GradientBoostingClassifier()]\n",
    "#names = [\"GradBoost\"]\n",
    "#classifiers = [GradientBoostingClassifier()]\n",
    "names = [\"KNN\", \"SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\",\\\n",
    "        \"Adaboost\", \"GradBoost\", \"Naive Bayes\", \"QDA\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(gamma=2, C=1, probability=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "#names = [\"SVM\", \"Random Forest\", \"NeuralNet\"]\n",
    "\n",
    "def choose_classifier(data, labels):\n",
    "    best=0\n",
    "    cl_train, cl_test, cl_ytrain, cl_ytest = \\\n",
    "        train_test_split(data, labels, test_size=.4, random_state=42)\n",
    "    all_scores = []\n",
    "    for n, c in zip(names, classifiers):\n",
    "        print(n)\n",
    "        scores = cross_val_score(c, data, labels, scoring='f1',cv=10)\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "        # Train the classifier\n",
    "        c.fit(cl_train, cl_ytrain.ravel())\n",
    "\n",
    "        # Predict test data\n",
    "        y_test_predict = c.predict(cl_test)\n",
    "\n",
    "        # Get the classification accuracy\n",
    "        print(\"Accuracy: \" + str(scores.mean()) + '%')\n",
    "        print('-----------------------------------------')\n",
    "        if scores.mean() > best:\n",
    "            best_classifier = n\n",
    "            best = scores.mean()\n",
    "        all_scores+=[np.round(scores.mean()*100,2)]\n",
    "        \n",
    "    print('******** Best Classifier: ' + str(best_classifier) + ' ********')\n",
    "    print(all_scores)\n",
    "    return pd.DataFrame([all_scores], columns=names)\n",
    "\n",
    "\n",
    "def score_classifier(c, n, train, test, y_train, y_test, show=False):\n",
    "    all_scores = []\n",
    "\n",
    "    # Train the classifier\n",
    "    c.fit(train, y_train.ravel())\n",
    "\n",
    "    # Predict test data\n",
    "    y_pred = c.predict(test)\n",
    "    \n",
    "    #score = f1_score(y_test, y_pred, average='micro')\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    # Get the classification accuracy\n",
    "    print(str(n) + \" --- Accuracy: \" + str(score) + '%')\n",
    "    print('-----------------------------------------')\n",
    "    class_names = np.array(['Apnea', 'Normal'])\n",
    "    if show:\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "        plt.show()\n",
    "        \n",
    "    #return [np.round(score*100,2), np.round(accuracy*100,2)]\n",
    "    return np.round(score*100,2)\n",
    "\n",
    "def fus_classifier(cl, ns, train, test, y_train, y_test, show=False):\n",
    "    all_scores = []\n",
    "    \n",
    "    # Train the classifier\n",
    "    y_pred = []\n",
    "    \n",
    "    cl[0].fit(train, y_train.ravel())\n",
    "    cl[1].fit(train, y_train.ravel())\n",
    "    proba1 = cl[0].predict_proba(test)\n",
    "    proba2 = cl[1].predict_proba(test)\n",
    "    #prob = [proba1[pb] if np.argmax([proba1[pb], proba2[pb]]) in [0,1] else proba2[pb] for pb in range(len(proba1))]\n",
    "    prob= [[np.mean([proba1[i,0],proba2[i,0]]),np.mean([proba1[i,1],proba2[i,1]])] for i in range(len(proba1))]\n",
    "\n",
    "    \n",
    "    print(prob)\n",
    "    y_pred = [np.argmax(prob[i]) for i in range(len(prob))]\n",
    "    y_test = [1 if yt == 'N' else 0 for yt in y_test]\n",
    "    print(y_test, y_pred)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "        \n",
    "    #print(c.predict_proba(test))\n",
    "    # Get the classification accuracy\n",
    "    print(str(ns) + \" --- Accuracy: \" + str(score) + '%')\n",
    "    print('-----------------------------------------')\n",
    "    class_names = np.array(['Apnea', 'Normal'])\n",
    "    if show:\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    #return [np.round(score*100,2), np.round(accuracy*100,2)]\n",
    "    return np.round(score*100,2)\n",
    "\n",
    "\n",
    "\n",
    "def fusion_classifier(classifiers, names, train, test, y_train, y_test, show=False):\n",
    "    all_scores = []\n",
    "    \n",
    "    cl_score = []\n",
    "    \n",
    "    for n, c in zip(names, classifiers):\n",
    "    \n",
    "        c.fit(train, y_train.ravel())\n",
    "        \n",
    "        prob = c.predict_proba(test)\n",
    "        \n",
    "        if n == names[0]:\n",
    "            predictions = prob[0]\n",
    "        else:  \n",
    "            predictions = np.column_stack((np.maximum(predictions[0][:,0],prob[0][:,0]), np.maximum(predictions[0][:,1],prob[0][:,1])))\n",
    "\n",
    "    y_pred = [np.argmax(np.array(yi)) for yi in predictions]\n",
    "\n",
    "    print(y_pred)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    #accuracy = accuracy_score(y_test,y_pred)\n",
    "    # Get the classification accuracy\n",
    "    print(\" Fusion --- F1 Score: \" + str(score) + '%')\n",
    "    print('-----------------------------------------')\n",
    "    class_names = np.array(['Apnea', 'Normal'])\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()      \n",
    "        \n",
    "    #return [np.round(score*100,2), np.round(accuracy*100,2)]\n",
    "    return np.round(score*100,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 Folds \n",
    "\n",
    "Classifier is a fusion from SVM with Random Forest\n",
    "\n",
    "Autoencoder gives correlation values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 15)\n",
      "[10 20 30 33 34] [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 21 22 23 24 25\n",
      " 26 27 28 29 31 32 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 3  7 18 23 40] [ 0  1  2  4  5  6  8  9 10 11 12 13 14 15 16 17 19 20 21 22 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 2  6 35 37 39] [ 0  1  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 36 38 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[12 21 27 31 42] [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 22 23 24 25\n",
      " 26 28 29 30 32 33 34 35 36 37 38 39 40 41 43 44]\n",
      "(45, 15)\n",
      "[ 5 13 14 17 19] [ 0  1  2  3  4  6  7  8  9 10 11 12 15 16 18 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 1  4 26 43] [ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 44]\n",
      "(45, 15)\n",
      "[11 22 24 32] [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20 21 23 25 26\n",
      " 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 8 16 41 44] [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43]\n",
      "(45, 15)\n",
      "[25 28 29 38] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 26 27 30 31 32 33 34 35 36 37 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 0  9 15 36] [ 1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 3 19 26 31 35] [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
      " 27 28 29 30 32 33 34 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[14 21 25 37 38] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 22 23 24 26\n",
      " 27 28 29 30 31 32 33 34 35 36 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 0  1  9 29 36] [ 2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 30 31 32 33 34 35 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[10 16 27 39 41] [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 17 18 19 20 21 22 23 24 25\n",
      " 26 28 29 30 31 32 33 34 35 36 37 38 40 42 43 44]\n",
      "(45, 15)\n",
      "[ 6  8 13 15 23] [ 0  1  2  3  4  5  7  9 10 11 12 14 16 17 18 19 20 21 22 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 2 12 18 22] [ 0  1  3  4  5  6  7  8  9 10 11 13 14 15 16 17 19 20 21 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 4 30 34 40] [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 31 32 33 35 36 37 38 39 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 5 20 32 43] [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25\n",
      " 26 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 44]\n",
      "(45, 15)\n",
      "[28 33 42 44] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 34 35 36 37 38 39 40 41 43]\n",
      "(45, 15)\n",
      "[ 7 11 17 24] [ 0  1  2  3  4  5  6  8  9 10 12 13 14 15 16 18 19 20 21 22 23 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 1  4 10 19 27] [ 0  2  3  5  6  7  8  9 11 12 13 14 15 16 17 18 20 21 22 23 24 25 26 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 7  8 13 22 39] [ 0  1  2  3  4  5  6  9 10 11 12 14 15 16 17 18 19 20 21 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[11 36 37 42 43] [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 38 39 40 41 44]\n",
      "(45, 15)\n",
      "[ 2  6 21 28 34] [ 0  1  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24 25 26\n",
      " 27 29 30 31 32 33 35 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 0  5 24 31 41] [ 1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 25 26\n",
      " 27 28 29 30 32 33 34 35 36 37 38 39 40 42 43 44]\n",
      "(45, 15)\n",
      "[12 26 30 38] [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 27 28 29 31 32 33 34 35 36 37 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[ 9 32 33 40] [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 34 35 36 37 38 39 41 42 43 44]\n",
      "(45, 15)\n",
      "[15 17 25 35] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 18 19 20 21 22 23 24 26\n",
      " 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44]\n",
      "(45, 15)\n",
      "[14 16 20 44] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 17 18 19 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "(45, 15)\n",
      "[ 3 18 23 29] [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 21 22 24 25 26\n",
      " 27 28 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "Y = np.array(user_labs)\n",
    "FS_X = np.array(user_data)\n",
    "FS_X_train = [0]*30\n",
    "FS_X_test = [0]*30\n",
    "y_test = [0]*30\n",
    "y_train = [0]*30\n",
    "fold = 0\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats = 3,random_state=10)\n",
    "\n",
    "for train_index, test_index in kf.split(Y):\n",
    "    print(Y.shape)\n",
    "    print(test_index, train_index)\n",
    "    FS_X_train[fold] = np.vstack(FS_X[train_index])\n",
    "    y_train[fold] = np.concatenate(Y[train_index], axis=0)\n",
    "    FS_X_test[fold] = np.vstack(FS_X[test_index])\n",
    "    y_test[fold] = np.concatenate(Y[test_index], axis=0)\n",
    "    fold +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.1704 - val_loss: -0.7673\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8161 - val_loss: -0.8835\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8962 - val_loss: -0.8989\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9003\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9074 - val_loss: -0.9004\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9075 - val_loss: -0.9005\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9075 - val_loss: -0.9006\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9077 - val_loss: -0.9008\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.9010\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9082 - val_loss: -0.9012\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9085 - val_loss: -0.9014\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9089 - val_loss: -0.9016\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9092 - val_loss: -0.9019\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9096 - val_loss: -0.9022\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9102 - val_loss: -0.9027\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9108 - val_loss: -0.9034\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9117 - val_loss: -0.9041\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9127 - val_loss: -0.9052\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9141 - val_loss: -0.9066\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9159 - val_loss: -0.9085\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9185 - val_loss: -0.9109\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9128\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9134\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9147\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9257 - val_loss: -0.9149\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9255 - val_loss: -0.9136\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9163\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9270 - val_loss: -0.9156\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9274 - val_loss: -0.9165\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9282 - val_loss: -0.9167\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9282 - val_loss: -0.9173\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9286 - val_loss: -0.9173\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9289 - val_loss: -0.9170\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9284 - val_loss: -0.9140\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9168\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9283 - val_loss: -0.9165\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9280 - val_loss: -0.9168\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9289 - val_loss: -0.9175\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9288 - val_loss: -0.9177\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9293 - val_loss: -0.9179\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9292 - val_loss: -0.9155\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9270 - val_loss: -0.9178\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9285 - val_loss: -0.9177\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9288 - val_loss: -0.9176\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9290 - val_loss: -0.9176\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9293 - val_loss: -0.9178\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9295 - val_loss: -0.9180\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9296 - val_loss: -0.9176\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9282 - val_loss: -0.9176\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9288 - val_loss: -0.9130\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 800us/step\n",
      "19/19 [==============================] - 0s 900us/step\n",
      "[[0.32011074985706417, 0.6798892501429359], [0.09198532199492895, 0.9080146780050711], [0.09352103023785374, 0.9064789697621464], [0.36280703917650525, 0.6371929608234947], [0.13421510577820683, 0.8657848942217932], [0.03434991472051471, 0.9656500852794854], [0.02407435230924281, 0.9759256476907574], [0.024189832952347116, 0.9758101670476529], [0.095315202433781, 0.9046847975662189], [0.061997568962412486, 0.9380024310375874], [0.34632963598898164, 0.6536703640110184], [0.5926460483407129, 0.4073539516592871], [0.5911904447054181, 0.4088095552945818], [0.6486195954404315, 0.3513804045595686], [0.6270513562122053, 0.3729486437877946], [0.15618017743297452, 0.8438198225670255], [0.25507881807567007, 0.74492118192433], [0.13342386904651102, 0.866576130953489], [0.34693639560899814, 0.6530636043910019], [0.1603331478267866, 0.8396668521732134], [0.3144026242363704, 0.6855973757636297], [0.27290852363561713, 0.7270914763643828], [0.37458809913550384, 0.6254119008644962], [0.4091675836280918, 0.5908324163719082], [0.5009600221634667, 0.4990399778365334], [0.51993111524545, 0.48006888475454995], [0.6895281500064148, 0.3104718499935851], [0.44661378979705574, 0.5533862102029443], [0.11142944631008912, 0.8885705536899109], [0.28748098462529703, 0.712519015374703], [0.3734662244817808, 0.6265337755182192], [0.6155394817128786, 0.3844605182871213], [0.538093341615445, 0.4619066583845549], [0.11276513456153711, 0.887234865438463], [0.17529433359810198, 0.824705666401898], [0.08214557529509085, 0.9178544247049092], [0.042746282636493334, 0.9572537173635067], [0.26646332501026027, 0.7335366749897396], [0.11895160363266147, 0.8810483963673386], [0.09446432082132512, 0.9055356791786748], [0.3188885064155314, 0.6811114935844684], [0.5635634443478295, 0.43643655565217077], [0.5931530545422958, 0.4068469454577043], [0.7016003467219254, 0.29839965327807444], [0.4058634581127914, 0.5941365418872087], [0.15978274335848616, 0.8402172566415138], [0.1821339052328571, 0.8178660947671429], [0.3166711941062351, 0.683328805893765], [0.24968980263570487, 0.7503101973642953], [0.38532397966675813, 0.6146760203332419], [0.03603437209028928, 0.9639656279097109], [0.024288015358896256, 0.9757119846411039], [0.022267886918237965, 0.977732113081762], [0.03058974827666377, 0.9694102517233363], [0.03171662568101521, 0.9682833743189848], [0.2029937684248098, 0.7970062315751902], [0.46913423438951374, 0.5308657656104864], [0.685937344008364, 0.31406265599163585], [0.6226472401666951, 0.37735275983330496], [0.6143022280997815, 0.3856977719002185], [0.2098505538490104, 0.7901494461509897], [0.3591259243259667, 0.6408740756740332], [0.1265976890664575, 0.8734023109335425], [0.32151398536757547, 0.6784860146324246], [0.11002169526071878, 0.8899783047392811], [0.10694787469331417, 0.8930521253066859], [0.02307826953297082, 0.9769217304670293], [0.020909520322344128, 0.9790904796776558], [0.3943769347303445, 0.6056230652696555], [0.44229704250981083, 0.557702957490189], [0.4510977191956036, 0.5489022808043964], [0.5506379086236632, 0.44936209137633687], [0.7143814555463158, 0.2856185444536842], [0.3970321562931861, 0.6029678437068139], [0.6213302025897514, 0.37866979741024875]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8266666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.1962 - val_loss: -0.7647\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8139 - val_loss: -0.8845\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8935 - val_loss: -0.8972\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9016 - val_loss: -0.8984\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9025 - val_loss: -0.8988\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9029 - val_loss: -0.8991\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9031 - val_loss: -0.8992\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9032 - val_loss: -0.8994\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9034 - val_loss: -0.8996\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9036 - val_loss: -0.8998\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9038 - val_loss: -0.9000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9003\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9044 - val_loss: -0.9006\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9047 - val_loss: -0.9009\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9051 - val_loss: -0.9013\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9056 - val_loss: -0.9018\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9062 - val_loss: -0.9024\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9071 - val_loss: -0.9033\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9081 - val_loss: -0.9045\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9098 - val_loss: -0.9061\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9121 - val_loss: -0.9082\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9150 - val_loss: -0.9109\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9185 - val_loss: -0.9130\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9209 - val_loss: -0.9148\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9152\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9243 - val_loss: -0.9171\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9257 - val_loss: -0.9174\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9265 - val_loss: -0.9177\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9271 - val_loss: -0.9182\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9272 - val_loss: -0.9181\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9271 - val_loss: -0.9182\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9264 - val_loss: -0.9152\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9244 - val_loss: -0.9172\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9245 - val_loss: -0.9137\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9254 - val_loss: -0.9169\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9261 - val_loss: -0.9176\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9185\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9276 - val_loss: -0.9191\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9277 - val_loss: -0.9183\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9277 - val_loss: -0.9181\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9276 - val_loss: -0.9190\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9283 - val_loss: -0.9188\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9281 - val_loss: -0.9185\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9283 - val_loss: -0.9189\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9282 - val_loss: -0.9182\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9281 - val_loss: -0.9188\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9283 - val_loss: -0.9186\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9282 - val_loss: -0.9190\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9285 - val_loss: -0.9187\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9281 - val_loss: -0.9172\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 859us/step\n",
      "19/19 [==============================] - 0s 851us/step\n",
      "[[0.22924444435985175, 0.7707555556401482], [0.24033910656386598, 0.759660893436134], [0.16557116104406966, 0.8344288389559305], [0.21578399377843965, 0.7842160062215602], [0.22605015357300962, 0.7739498464269904], [0.1783097572084246, 0.8216902427915753], [0.369145145533636, 0.6308548544663641], [0.47195509197808105, 0.528044908021919], [0.11789460905013122, 0.8821053909498687], [0.35218303039563115, 0.6478169696043689], [0.511298704605047, 0.48870129539495294], [0.6593814934928686, 0.3406185065071314], [0.49701779624924386, 0.5029822037507561], [0.358678539717738, 0.641321460282262], [0.43469989626816974, 0.5653001037318302], [0.23070146198121694, 0.769298538018783], [0.47028020360944695, 0.5297197963905531], [0.5006415117801908, 0.4993584882198092], [0.3141991974752295, 0.6858008025247704], [0.3444972099200093, 0.6555027900799908], [0.11160317644141717, 0.8883968235585828], [0.06871315076495878, 0.9312868492350412], [0.2369848564134599, 0.76301514358654], [0.25915036578711936, 0.7408496342128805], [0.4885246531226147, 0.5114753468773853], [0.4415748416091113, 0.5584251583908886], [0.535487612668445, 0.46451238733155487], [0.39225612575305835, 0.6077438742469417], [0.6115285701152966, 0.3884714298847034], [0.4557606231131843, 0.5442393768868157], [0.31872066879089284, 0.6812793312091071], [0.6622947374446928, 0.3377052625553072], [0.2405411425748209, 0.759458857425179], [0.26093111779198697, 0.7390688822080129], [0.42885084287174496, 0.5711491571282551], [0.461210409001088, 0.538789590998912], [0.2570106557983082, 0.7429893442016918], [0.1827161008090318, 0.8172838991909681], [0.6304066767069912, 0.36959332329300876], [0.5498319328105284, 0.45016806718947155], [0.45755371100808884, 0.5424462889919113], [0.33261317937794965, 0.6673868206220503], [0.5398246687156424, 0.4601753312843575], [0.5435314603521691, 0.45646853964783085], [0.4501489927591744, 0.5498510072408258], [0.2640433718774451, 0.7359566281225549], [0.2626935898024153, 0.7373064101975847], [0.23242979113776865, 0.7675702088622314], [0.1691790217179514, 0.8308209782820487], [0.09701135339487266, 0.9029886466051273], [0.43287167857814735, 0.5671283214218528], [0.7065634150293563, 0.2934365849706436], [0.2355705490843087, 0.7644294509156914], [0.3789703004314158, 0.6210296995685841], [0.20183561769680552, 0.7981643823031945], [0.30235122291611044, 0.6976487770838895], [0.32834165393212156, 0.6716583460678784], [0.32898071677874097, 0.6710192832212589], [0.5179702657855089, 0.48202973421449113], [0.4777675554373946, 0.5222324445626054], [0.18247449642038352, 0.8175255035796165], [0.27606103898080214, 0.7239389610191977], [0.4035897436030292, 0.5964102563969708], [0.532481121423699, 0.46751887857630103], [0.23658735210198586, 0.7634126478980142], [0.00906996996131146, 0.9909300300386885], [0.011471463197476012, 0.9885285368025238], [0.4524333521256623, 0.5475666478743377], [0.264148481522985, 0.7358515184770149], [0.16474408945519975, 0.8352559105448003], [0.41691464155744085, 0.5830853584425592], [0.1705576438575523, 0.8294423561424478], [0.45510219680179903, 0.544897803198201], [0.4113431011213984, 0.5886568988786016], [0.46099769680640196, 0.539002303193598]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.68%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2720 - val_loss: -0.7992\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8370 - val_loss: -0.8919\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8964 - val_loss: -0.8997\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9011 - val_loss: -0.9003\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9016 - val_loss: -0.9006\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9020 - val_loss: -0.9009\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9023 - val_loss: -0.9012\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9026 - val_loss: -0.9014\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9030 - val_loss: -0.9017\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9033 - val_loss: -0.9020\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9037 - val_loss: -0.9024\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9029\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9049 - val_loss: -0.9035\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9056 - val_loss: -0.9044\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9070 - val_loss: -0.9058\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9088 - val_loss: -0.9076\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9111 - val_loss: -0.9100\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9143 - val_loss: -0.9129\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9175 - val_loss: -0.9152\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9199 - val_loss: -0.9165\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9217 - val_loss: -0.9176\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9229 - val_loss: -0.9182\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9233 - val_loss: -0.9183\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9235 - val_loss: -0.9179\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9237 - val_loss: -0.9187\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9243 - val_loss: -0.9184\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9243 - val_loss: -0.9196\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9164\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9233 - val_loss: -0.9150\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9208 - val_loss: -0.9163\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9224 - val_loss: -0.9166\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9224 - val_loss: -0.9175\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9240 - val_loss: -0.9177\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9241 - val_loss: -0.9167\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9190\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9241 - val_loss: -0.9189\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9244 - val_loss: -0.9199\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9249 - val_loss: -0.9199\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9255 - val_loss: -0.9194\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9249 - val_loss: -0.9192\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9200\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9195\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9178\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9181\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9167\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9238 - val_loss: -0.9189\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9194\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9253 - val_loss: -0.9199\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9258 - val_loss: -0.9198\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9256 - val_loss: -0.9204\n",
      "3/3 [==============================] - 0s 969us/step\n",
      "3/3 [==============================] - 0s 970us/step\n",
      "19/19 [==============================] - 0s 908us/step\n",
      "19/19 [==============================] - 0s 910us/step\n",
      "[[0.2838223097412728, 0.7161776902587271], [0.4608820276623457, 0.5391179723376542], [0.1644909419986536, 0.8355090580013463], [0.12058390603756944, 0.8794160939624306], [0.1882746938964233, 0.8117253061035767], [0.15609550657099422, 0.8439044934290058], [0.22779410757744342, 0.7722058924225566], [0.16115991022048498, 0.838840089779515], [0.21085976650799235, 0.7891402334920075], [0.2549885320577884, 0.7450114679422115], [0.3323885977650731, 0.6676114022349268], [0.6103928884560672, 0.3896071115439328], [0.5044012119349631, 0.4955987880650369], [0.4792329815150662, 0.5207670184849338], [0.5908238852945797, 0.40917611470542015], [0.27344501123059484, 0.7265549887694052], [0.21622266988161004, 0.7837773301183899], [0.3278352152100876, 0.6721647847899124], [0.19831399561560145, 0.8016860043843985], [0.18787723032580067, 0.8121227696741992], [0.3145052715435397, 0.6854947284564603], [0.538435875954957, 0.461564124045043], [0.07627896756771654, 0.9237210324322835], [0.026149437304621194, 0.9738505626953788], [0.055643583417700995, 0.9443564165822989], [0.4170513532298623, 0.5829486467701377], [0.5715720287715476, 0.4284279712284525], [0.4708814014559593, 0.5291185985440406], [0.32191318175631684, 0.6780868182436832], [0.48667700438794503, 0.5133229956120549], [0.1460317857924709, 0.8539682142075289], [0.20750306975661334, 0.7924969302433866], [0.27209865090679275, 0.7279013490932071], [0.45114833733336346, 0.5488516626666365], [0.3404078045216574, 0.6595921954783426], [0.5580360188139181, 0.441963981186082], [0.4954352231185132, 0.5045647768814867], [0.3771237300336249, 0.6228762699663751], [0.3456441855942053, 0.6543558144057946], [0.5473177873435681, 0.452682212656432], [0.48906488494985956, 0.5109351150501404], [0.4967448268515138, 0.5032551731484863], [0.41726693429042244, 0.5827330657095775], [0.43173123726523643, 0.5682687627347636], [0.4245873306410537, 0.5754126693589463], [0.5595736991079321, 0.4404263008920679], [0.3725218054070041, 0.6274781945929959], [0.1700798698812354, 0.8299201301187645], [0.15609736524943024, 0.8439026347505697], [0.12241600884556393, 0.8775839911544359], [0.16703861400555148, 0.8329613859944485], [0.18806725840113564, 0.8119327415988644], [0.20685865526574004, 0.7931413447342598], [0.206710970862715, 0.7932890291372849], [0.11770696169957352, 0.8822930383004264], [0.4545538397768595, 0.5454461602231405], [0.17952894406867434, 0.8204710559313255], [0.35936392039131915, 0.640636079608681], [0.4728537729262511, 0.5271462270737488], [0.3184195323178552, 0.6815804676821449], [0.17098928341840242, 0.8290107165815975], [0.45940193316173694, 0.5405980668382631], [0.16849394774866883, 0.8315060522513311], [0.1755105495402539, 0.8244894504597461], [0.32135190734495767, 0.6786480926550423], [0.09032555152783764, 0.9096744484721624], [0.012953215622185613, 0.9870467843778143], [0.011372089789837043, 0.9886279102101629], [0.03849053460175726, 0.9615094653982428], [0.01057329355298846, 0.9894267064470115], [0.4776040826574086, 0.5223959173425914], [0.3238854041456396, 0.6761145958543604], [0.40432755629679473, 0.5956724437032053], [0.7883684197848753, 0.21163158021512488], [0.643469252851725, 0.3565307471482751]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.6933333333333334%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.1823 - val_loss: -0.7685\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8149 - val_loss: -0.8881\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8938 - val_loss: -0.9008\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9020\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9027 - val_loss: -0.9023\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9029 - val_loss: -0.9026\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9031 - val_loss: -0.9027\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9032 - val_loss: -0.9028\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9034 - val_loss: -0.9030\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9035 - val_loss: -0.9031\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9037 - val_loss: -0.9033\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.9035\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9037\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9044 - val_loss: -0.9039\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9041\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9048 - val_loss: -0.9044\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9052 - val_loss: -0.9048\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9055 - val_loss: -0.9052\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9060 - val_loss: -0.9058\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9065\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9075 - val_loss: -0.9076\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9089 - val_loss: -0.9088\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9106 - val_loss: -0.9108\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9131 - val_loss: -0.9129\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9158 - val_loss: -0.9146\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9182 - val_loss: -0.9159\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9199 - val_loss: -0.9169\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9162\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9213 - val_loss: -0.9161\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9181\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9217 - val_loss: -0.9094\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9163 - val_loss: -0.9140\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9199 - val_loss: -0.9180\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9218 - val_loss: -0.9185\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9233 - val_loss: -0.9184\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9233 - val_loss: -0.9171\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9222 - val_loss: -0.9169\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9226 - val_loss: -0.9181\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9227 - val_loss: -0.9190\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9233 - val_loss: -0.9193\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9229 - val_loss: -0.9196\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9241 - val_loss: -0.9188\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9193\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9243 - val_loss: -0.9194\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9200\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9247 - val_loss: -0.9195\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9198\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9198\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9250 - val_loss: -0.9198\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9199\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 810us/step\n",
      "19/19 [==============================] - 0s 834us/step\n",
      "[[0.21455882095993908, 0.785441179040061], [0.35154026501615077, 0.6484597349838492], [0.24469670621221684, 0.755303293787783], [0.1253692195374275, 0.8746307804625725], [0.5125928059457815, 0.48740719405421845], [0.17128491459690925, 0.8287150854030908], [0.023464574250633446, 0.9765354257493666], [0.019813022114925187, 0.9801869778850749], [0.008853535358590922, 0.991146464641409], [0.020075326664708393, 0.9799246733352915], [0.5181905514236582, 0.4818094485763417], [0.6601863054087604, 0.33981369459123945], [0.392681773383173, 0.6073182266168271], [0.6631750807687626, 0.3368249192312374], [0.5322983096772996, 0.46770169032270026], [0.47185724363497705, 0.528142756365023], [0.25081603753363424, 0.7491839624663659], [0.25104097690650695, 0.748959023093493], [0.195188565812435, 0.804811434187565], [0.17950678548532595, 0.8204932145146742], [0.014791058208084785, 0.9852089417919152], [0.01611622847092321, 0.9838837715290767], [0.008994277521992588, 0.9910057224780073], [0.013213115194573074, 0.986786884805427], [0.017514970455253933, 0.982485029544746], [0.48535424952857253, 0.5146457504714275], [0.5642641161612407, 0.4357358838387593], [0.3967955055333148, 0.6032044944666852], [0.3097504133162977, 0.6902495866837023], [0.5982649609206425, 0.4017350390793575], [0.36214256196986794, 0.6378574380301321], [0.3221048699560506, 0.6778951300439495], [0.677496691666531, 0.32250330833346896], [0.5202143389073448, 0.4797856610926551], [0.6759857586456619, 0.32401424135433804], [0.47371413620139186, 0.5262858637986082], [0.3358809301555208, 0.6641190698444792], [0.3387987346991941, 0.6612012653008059], [0.18592101120997512, 0.814078988790025], [0.6406958413171073, 0.35930415868289267], [0.635074521571495, 0.364925478428505], [0.5003122628095851, 0.499687737190415], [0.1944230301204301, 0.8055769698795698], [0.5295696426998348, 0.47043035730016525], [0.30206467559571226, 0.697935324404288], [0.22295627614561297, 0.7770437238543871], [0.4805414516638551, 0.5194585483361449], [0.26585899177712347, 0.7341410082228763], [0.35759496767378307, 0.6424050323262169], [0.4090404686397513, 0.5909595313602487], [0.17060673637057597, 0.8293932636294241], [0.03477754757408834, 0.9652224524259116], [0.07065666788075646, 0.9293433321192435], [0.11402880922286796, 0.885971190777132], [0.07076153582069415, 0.9292384641793059], [0.7006442768572245, 0.29935572314277537], [0.48929333643130724, 0.5107066635686927], [0.5653154070081274, 0.4346845929918725], [0.7733287692344687, 0.2266712307655314], [0.4450037719761701, 0.5549962280238301], [0.3762385833153199, 0.6237614166846801], [0.5072157679463029, 0.49278423205369704], [0.42018821129440576, 0.5798117887055942], [0.7750625588589883, 0.22493744114101166], [0.6503601582821048, 0.3496398417178951], [0.08321893659615637, 0.9167810634038436], [0.02236658827914975, 0.9776334117208503], [0.018982165905328995, 0.9810178340946711], [0.3718146090690254, 0.6281853909309745], [0.014520853162746226, 0.9854791468372538], [0.458348461752299, 0.541651538247701], [0.6982399168636408, 0.3017600831363591], [0.32154165986601857, 0.6784583401339814], [0.6769499180711124, 0.3230500819288875], [0.4294159612191225, 0.5705840387808774]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7466666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: -0.2815 - val_loss: -0.8071\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8411 - val_loss: -0.8917\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8954 - val_loss: -0.8994\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9001 - val_loss: -0.8998\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9003 - val_loss: -0.9000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9004 - val_loss: -0.9002\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9006 - val_loss: -0.9004\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9008 - val_loss: -0.9006\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9010 - val_loss: -0.9007\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9011 - val_loss: -0.9009\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: -0.9014 - val_loss: -0.9011\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9016 - val_loss: -0.9014\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9017\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9021 - val_loss: -0.9020\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9023 - val_loss: -0.9023\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9026 - val_loss: -0.9026\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9028 - val_loss: -0.9030\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9032 - val_loss: -0.9034\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9036 - val_loss: -0.9039\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9048\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9049 - val_loss: -0.9060\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9060 - val_loss: -0.9076\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9074 - val_loss: -0.9100\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9098 - val_loss: -0.9134\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9125 - val_loss: -0.9168\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9153 - val_loss: -0.9196\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9171 - val_loss: -0.9216\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9183 - val_loss: -0.9212\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: -0.9183 - val_loss: -0.9229\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9193 - val_loss: -0.9219\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9191 - val_loss: -0.9229\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9195 - val_loss: -0.9229\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9189 - val_loss: -0.9224\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9190 - val_loss: -0.9204\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9184 - val_loss: -0.9186\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9174 - val_loss: -0.9215\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9148 - val_loss: -0.9222\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9162 - val_loss: -0.9158\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9141 - val_loss: -0.9221\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9186 - val_loss: -0.9233\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9203 - val_loss: -0.9239\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9199 - val_loss: -0.9231\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9206 - val_loss: -0.9249\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9207 - val_loss: -0.9248\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9208 - val_loss: -0.9244\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9204 - val_loss: -0.9237\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9200 - val_loss: -0.9240\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9201 - val_loss: -0.9245\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9202 - val_loss: -0.9238\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9202 - val_loss: -0.9219\n",
      "3/3 [==============================] - 0s 988us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 820us/step\n",
      "19/19 [==============================] - 0s 823us/step\n",
      "[[0.6522825105916938, 0.34771748940830616], [0.47915842851561286, 0.5208415714843871], [0.29817867501967443, 0.7018213249803256], [0.4850628419330921, 0.5149371580669079], [0.22512395033116728, 0.7748760496688327], [0.15318441969997265, 0.8468155803000275], [0.20183525126438423, 0.7981647487356158], [0.06110742962597088, 0.9388925703740292], [0.025453191488330206, 0.9745468085116697], [0.04748394235505302, 0.9525160576449468], [0.16644782082369675, 0.8335521791763032], [0.41592018580685763, 0.5840798141931424], [0.4026830788146283, 0.5973169211853715], [0.7046512055055851, 0.2953487944944151], [0.5383278654778157, 0.46167213452218425], [0.3890991773479947, 0.6109008226520053], [0.4657226147682121, 0.5342773852317879], [0.13200290261584596, 0.867997097384154], [0.21756619491991433, 0.7824338050800855], [0.31072472169574994, 0.68927527830425], [0.023967555825571474, 0.9760324441744287], [0.1103564859943971, 0.8896435140056029], [0.12871483761590047, 0.8712851623840996], [0.3128990932016456, 0.6871009067983544], [0.27017891642239833, 0.7298210835776017], [0.3825078247223154, 0.6174921752776847], [0.4998901881624769, 0.5001098118375231], [0.45576745432037863, 0.5442325456796213], [0.507248888645238, 0.4927511113547619], [0.38818153826001867, 0.6118184617399813], [0.32736541675854136, 0.6726345832414586], [0.745704297746846, 0.2542957022531541], [0.27594062501457617, 0.7240593749854238], [0.3264243446013001, 0.6735756553986998], [0.15817328035806508, 0.8418267196419349], [0.15791950296331517, 0.8420804970366849], [0.41031235810756095, 0.589687641892439], [0.484538823129502, 0.515461176870498], [0.3359364046681669, 0.6640635953318332], [0.4985811002670614, 0.5014188997329386], [0.5281552380069132, 0.47184476199308695], [0.5147730174855194, 0.4852269825144806], [0.1859089829302666, 0.8140910170697335], [0.4377966591559166, 0.5622033408440834], [0.2941776283430546, 0.7058223716569454], [0.34786615505781504, 0.652133844942185], [0.23210541074830465, 0.7678945892516953], [0.23852452715480504, 0.7614754728451949], [0.3573499627418852, 0.6426500372581148], [0.48894287470250697, 0.5110571252974931], [0.03845165143929469, 0.9615483485607053], [0.05681126881395461, 0.9431887311860454], [0.09308164643678735, 0.9069183535632127], [0.2960575224421707, 0.7039424775578293], [0.15328856467088978, 0.8467114353291102], [0.37407002470207906, 0.6259299752979209], [0.38677189136776247, 0.6132281086322375], [0.7188427272237009, 0.281157272776299], [0.4160503104536588, 0.5839496895463413], [0.5644965443788189, 0.4355034556211811], [0.18216917748167166, 0.8178308225183284], [0.4916530539916162, 0.508346946008384], [0.6906905087564525, 0.3093094912435475], [0.3443163172084005, 0.6556836827915995], [0.1110192010657014, 0.8889807989342986], [0.38767799044579543, 0.6123220095542045], [0.4795892951212508, 0.5204107048787492], [0.28705948402978665, 0.7129405159702134], [0.3407122015100898, 0.6592877984899101], [0.3472058893953123, 0.6527941106046877], [0.4996785744462845, 0.5003214255537155], [0.38677808198851826, 0.6132219180114817], [0.3843667166666069, 0.6156332833333932], [0.3892047224637794, 0.6107952775362206], [0.6652661127601416, 0.3347338872398584]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7333333333333333%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.2465 - val_loss: -0.7807\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8269 - val_loss: -0.8900\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8970 - val_loss: -0.9014\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9038 - val_loss: -0.9021\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9021\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9021\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9022\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9043 - val_loss: -0.9024\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9026\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9047 - val_loss: -0.9028\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9048 - val_loss: -0.9030\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9051 - val_loss: -0.9032\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9053 - val_loss: -0.9034\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9055 - val_loss: -0.9036\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9057 - val_loss: -0.9039\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9059 - val_loss: -0.9043\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9062 - val_loss: -0.9046\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9050\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9070 - val_loss: -0.9056\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9076 - val_loss: -0.9063\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9084 - val_loss: -0.9074\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9095 - val_loss: -0.9090\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9113 - val_loss: -0.9111\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9136 - val_loss: -0.9134\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9163 - val_loss: -0.9161\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9190 - val_loss: -0.9179\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9190\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9225 - val_loss: -0.9207\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9213\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9243 - val_loss: -0.9180\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9224 - val_loss: -0.9212\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9246 - val_loss: -0.9215\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9212\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9205\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9252 - val_loss: -0.9216\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9227\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9230\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9264 - val_loss: -0.9235\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9267 - val_loss: -0.9238\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9269 - val_loss: -0.9233\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9266 - val_loss: -0.9228\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9261 - val_loss: -0.9211\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9256 - val_loss: -0.9231\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9229\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9261 - val_loss: -0.9179\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9242 - val_loss: -0.9214\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9206\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9237 - val_loss: -0.9230\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9224\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9263 - val_loss: -0.9235\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 848us/step\n",
      "20/20 [==============================] - 0s 822us/step\n",
      "[[0.19787342336847905, 0.8021265766315209], [0.15594094140753978, 0.8440590585924603], [0.20702177431030194, 0.792978225689698], [0.1743650721017434, 0.8256349278982567], [0.15482398290751964, 0.8451760170924805], [0.01475898471336488, 0.9852410152866351], [0.018354494680135253, 0.9816455053198647], [0.010012436548728482, 0.9899875634512716], [0.016548399591361306, 0.9834516004086387], [0.7867605255395902, 0.2132394744604099], [0.5188150991041519, 0.4811849008958482], [0.5395817181655428, 0.4604182818344573], [0.2479019168997283, 0.7520980831002717], [0.3119223526280029, 0.6880776473719971], [0.7341305311232488, 0.2658694688767512], [0.13565027435162766, 0.8643497256483723], [0.24562320368804752, 0.7543767963119526], [0.4075668244674703, 0.5924331755325296], [0.23041111348767912, 0.7695888865123207], [0.36390056890260625, 0.6360994310973938], [0.12012846316857281, 0.8798715368314272], [0.05245558244825602, 0.9475444175517441], [0.3684317967662947, 0.6315682032337053], [0.20437418679881858, 0.7956258132011814], [0.19735248391493815, 0.8026475160850619], [0.7760010514906072, 0.22399894850939284], [0.6581916262238707, 0.34180837377612927], [0.8236693442208962, 0.17633065577910378], [0.5517961759190033, 0.4482038240809967], [0.31279071320331986, 0.6872092867966801], [0.3488088432697688, 0.6511911567302311], [0.16841919115214604, 0.831580808847854], [0.11766228256668815, 0.8823377174333119], [0.23424659547386867, 0.7657534045261313], [0.30392285911437633, 0.6960771408856237], [0.694808916490278, 0.3051910835097219], [0.345443121822624, 0.6545568781773761], [0.23794624693184066, 0.7620537530681593], [0.22052995111653106, 0.7794700488834689], [0.27815847393313764, 0.7218415260668624], [0.495598078220313, 0.5044019217796869], [0.504543980447636, 0.49545601955236407], [0.8991224016999356, 0.10087759830006442], [0.3727852652325395, 0.6272147347674606], [0.3926411694799461, 0.6073588305200539], [0.17274946927877932, 0.8272505307212207], [0.25099828207684405, 0.7490017179231561], [0.22478048865293485, 0.7752195113470653], [0.13035682739343768, 0.8696431726065623], [0.15182776705704545, 0.8481722329429546], [0.54912588578588, 0.45087411421412005], [0.3305418873038463, 0.6694581126961537], [0.4513352016701151, 0.5486647983298849], [0.3502337585001518, 0.6497662414998482], [0.24812891434163653, 0.7518710856583635], [0.208887938892522, 0.791112061107478], [0.440981118025937, 0.5590188819740629], [0.7759409905233863, 0.22405900947661378], [0.8200368597952017, 0.17996314020479834], [0.5054999336117982, 0.49450006638820176]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8166666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.1956 - val_loss: -0.7671\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8172 - val_loss: -0.8856\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8948 - val_loss: -0.8993\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9033 - val_loss: -0.9005\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9040 - val_loss: -0.9006\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9007\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9008\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9044 - val_loss: -0.9011\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9046 - val_loss: -0.9013\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9049 - val_loss: -0.9016\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9052 - val_loss: -0.9019\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9055 - val_loss: -0.9023\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9059 - val_loss: -0.9027\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9063 - val_loss: -0.9031\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9069 - val_loss: -0.9038\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9077 - val_loss: -0.9045\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9086 - val_loss: -0.9055\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9099 - val_loss: -0.9070\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9118 - val_loss: -0.9090\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9141 - val_loss: -0.9115\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9171 - val_loss: -0.9134\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9193 - val_loss: -0.9156\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9222 - val_loss: -0.9157\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9209 - val_loss: -0.9173\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9241 - val_loss: -0.9186\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9253 - val_loss: -0.9190\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9250 - val_loss: -0.9187\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9129\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9204 - val_loss: -0.9074\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9194 - val_loss: -0.9163\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9238 - val_loss: -0.9177\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9257 - val_loss: -0.9192\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9257 - val_loss: -0.9200\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9263 - val_loss: -0.9181\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9261 - val_loss: -0.9198\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9267 - val_loss: -0.9201\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9270 - val_loss: -0.9199\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9198\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9199\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9199\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9272 - val_loss: -0.9203\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9190\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9269 - val_loss: -0.9203\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9200\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9199\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9192\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9189\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9267 - val_loss: -0.9207\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9268 - val_loss: -0.9196\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9270 - val_loss: -0.9191\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 766us/step\n",
      "20/20 [==============================] - 0s 751us/step\n",
      "[[0.4181423808795669, 0.5818576191204331], [0.5112632934512421, 0.4887367065487579], [0.7252919942485764, 0.27470800575142357], [0.43088846521544505, 0.569111534784555], [0.3321131601440934, 0.6678868398559066], [0.3480192217539495, 0.6519807782460505], [0.4742286314130617, 0.5257713685869383], [0.4477023330533286, 0.5522976669466713], [0.4248319693718613, 0.5751680306281387], [0.5658271066786715, 0.43417289332132847], [0.4292437803560576, 0.5707562196439424], [0.7811544616034871, 0.21884553839651286], [0.5834736909165102, 0.41652630908348975], [0.3117630705204345, 0.6882369294795656], [0.3187857236512994, 0.6812142763487006], [0.26869756429215436, 0.7313024357078457], [0.4322688139456461, 0.5677311860543539], [0.3853247848972735, 0.6146752151027265], [0.3119677007309911, 0.6880322992690089], [0.1857740422613554, 0.8142259577386446], [0.028553486853416243, 0.9714465131465837], [0.031134776099164114, 0.968865223900836], [0.0319726471200013, 0.9680273528799987], [0.03198848305206314, 0.9680115169479369], [0.02585290581565917, 0.9741470941843409], [0.5781538943716705, 0.42184610562832947], [0.38124353652435694, 0.6187564634756431], [0.17301351391562694, 0.826986486084373], [0.585548531692246, 0.41445146830775403], [0.37008903011392835, 0.6299109698860716], [0.5743956194773858, 0.4256043805226142], [0.3865788267094885, 0.6134211732905116], [0.51579326508623, 0.4842067349137701], [0.11615121419917299, 0.883848785800827], [0.25349823678220773, 0.7465017632177922], [0.024067653393561823, 0.9759323466064382], [0.04746353008688214, 0.9525364699131178], [0.040694928285187296, 0.9593050717148127], [0.21686604319379457, 0.7831339568062055], [0.027641443586396353, 0.9723585564136036], [0.5486753948563827, 0.4513246051436173], [0.5539866813415584, 0.4460133186584418], [0.7020848703698063, 0.29791512963019373], [0.637757229710736, 0.36224277028926394], [0.7692264571436715, 0.23077354285632828], [0.30589107665847537, 0.6941089233415246], [0.15518150377522816, 0.8448184962247718], [0.11278217975836274, 0.8872178202416373], [0.15446663213456188, 0.8455333678654382], [0.12752983585756775, 0.8724701641424323], [0.16446452548318086, 0.8355354745168192], [0.24936620091989853, 0.7506337990801015], [0.39958091272437213, 0.6004190872756279], [0.34677543529614696, 0.653224564703853], [0.2630633196082326, 0.7369366803917674], [0.6572036005774521, 0.3427963994225479], [0.45996221827850203, 0.5400377817214979], [0.3130229246663693, 0.6869770753336306], [0.4117938268462288, 0.5882061731537713], [0.5402513352571217, 0.4597486647428783]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7666666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.2311 - val_loss: -0.7916\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8363 - val_loss: -0.8905\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8991 - val_loss: -0.9003\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9053 - val_loss: -0.9012\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9058 - val_loss: -0.9014\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9060 - val_loss: -0.9016\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9062 - val_loss: -0.9018\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9020\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9022\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9068 - val_loss: -0.9023\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9070 - val_loss: -0.9025\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9072 - val_loss: -0.9028\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9075 - val_loss: -0.9030\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9078 - val_loss: -0.9033\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9081 - val_loss: -0.9036\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9085 - val_loss: -0.9041\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9089 - val_loss: -0.9046\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9095 - val_loss: -0.9053\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9103 - val_loss: -0.9063\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9114 - val_loss: -0.9077\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9129 - val_loss: -0.9097\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9150 - val_loss: -0.9117\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9170 - val_loss: -0.9138\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9192 - val_loss: -0.9154\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9208 - val_loss: -0.9169\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9221 - val_loss: -0.9182\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9191\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9236 - val_loss: -0.9194\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9237 - val_loss: -0.9181\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9226 - val_loss: -0.9168\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9216 - val_loss: -0.9198\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9244 - val_loss: -0.9197\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9208\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9258 - val_loss: -0.9208\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9203\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9208\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9210\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9262 - val_loss: -0.9210\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9199\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9254 - val_loss: -0.9199\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9194\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9208\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9243 - val_loss: -0.9183\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9210\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9262 - val_loss: -0.9215\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9266 - val_loss: -0.9216\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9266 - val_loss: -0.9216\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9267 - val_loss: -0.9212\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9255 - val_loss: -0.9194\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9258 - val_loss: -0.9186\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 745us/step\n",
      "20/20 [==============================] - 0s 812us/step\n",
      "[[0.5091005182369666, 0.49089948176303344], [0.16625962480557405, 0.833740375194426], [0.16509727117559872, 0.8349027288244013], [0.19600339728307273, 0.8039966027169272], [0.4445183587262223, 0.5554816412737777], [0.03463828178796794, 0.965361718212032], [0.031337052863210674, 0.9686629471367894], [0.031557470442127054, 0.968442529557873], [0.02193811206554219, 0.9780618879344578], [0.031032418720473742, 0.9689675812795262], [0.3717676932515711, 0.6282323067484288], [0.6260986158711157, 0.3739013841288843], [0.4374301706808051, 0.562569829319195], [0.4700995472164946, 0.5299004527835054], [0.2877920987238694, 0.7122079012761304], [0.3915155158723911, 0.6084844841276088], [0.4042492881744043, 0.5957507118255956], [0.19923164554007883, 0.8007683544599211], [0.27360857351453255, 0.7263914264854674], [0.4974942906404336, 0.5025057093595664], [0.25348433271802273, 0.7465156672819772], [0.46770127726356625, 0.5322987227364337], [0.47926380688739284, 0.5207361931126072], [0.21783868007740936, 0.7821613199225905], [0.15471441914164924, 0.8452855808583507], [0.2562582212411164, 0.7437417787588836], [0.3727150549650664, 0.6272849450349336], [0.6372261548939161, 0.3627738451060839], [0.5106100514405808, 0.4893899485594192], [0.46762899447985284, 0.5323710055201473], [0.26327929995193966, 0.7367207000480603], [0.15726815372573327, 0.8427318462742666], [0.15189241312352159, 0.8481075868764785], [0.22785891782235398, 0.772141082177646], [0.23154496113031847, 0.7684550388696815], [0.27878860598192867, 0.7212113940180713], [0.2963200829316352, 0.7036799170683647], [0.05581372720970068, 0.9441862727902992], [0.3835778375928306, 0.6164221624071693], [0.5539658825088047, 0.44603411749119537], [0.3765441831027406, 0.6234558168972593], [0.5351949194122557, 0.4648050805877443], [0.5403297107508285, 0.45967028924917164], [0.721174384312482, 0.27882561568751807], [0.5181931636983915, 0.48180683630160837], [0.4442266469140658, 0.5557733530859341], [0.1981234139247435, 0.8018765860752565], [0.1868042001194797, 0.8131957998805202], [0.2704593091591711, 0.7295406908408288], [0.20647976846056024, 0.7935202315394397], [0.28003670504023553, 0.7199632949597645], [0.051284038664939, 0.9487159613350611], [0.08924483296602934, 0.9107551670339706], [0.014013831196028883, 0.985986168803971], [0.07859277831308585, 0.9214072216869141], [0.7591504165813692, 0.2408495834186309], [0.711944363262535, 0.2880556367374651], [0.16493972056123624, 0.8350602794387637], [0.34451178609575406, 0.6554882139042459], [0.7371215783603423, 0.2628784216396577]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2596 - val_loss: -0.7932\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8293 - val_loss: -0.8953\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8934 - val_loss: -0.9042\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8987 - val_loss: -0.9048\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.8991 - val_loss: -0.9051\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8994 - val_loss: -0.9053\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.8996 - val_loss: -0.9055\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8998 - val_loss: -0.9058\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9001 - val_loss: -0.9060\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9003 - val_loss: -0.9063\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9007 - val_loss: -0.9067\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9012 - val_loss: -0.9071\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9076\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9026 - val_loss: -0.9084\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9036 - val_loss: -0.9094\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9052 - val_loss: -0.9110\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9074 - val_loss: -0.9132\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9106 - val_loss: -0.9158\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9138 - val_loss: -0.9178\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9163 - val_loss: -0.9194\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9182 - val_loss: -0.9201\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9192 - val_loss: -0.9211\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9203 - val_loss: -0.9218\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9217\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9211 - val_loss: -0.9225\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9217 - val_loss: -0.9204\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9200 - val_loss: -0.9212\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9194 - val_loss: -0.9214\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9211 - val_loss: -0.9223\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9220 - val_loss: -0.9203\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9210 - val_loss: -0.9224\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9219 - val_loss: -0.9223\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9224 - val_loss: -0.9229\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9230 - val_loss: -0.9236\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9234\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9233\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9233\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9237 - val_loss: -0.9231\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9237 - val_loss: -0.9234\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: -0.9237 - val_loss: -0.9234\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9223\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9216 - val_loss: -0.9231\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9216 - val_loss: -0.9203\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9213 - val_loss: -0.9216\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9214 - val_loss: -0.9230\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9230 - val_loss: -0.9229\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9234 - val_loss: -0.9228\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9233 - val_loss: -0.9214\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9227 - val_loss: -0.9232\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9231 - val_loss: -0.9227\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 795us/step\n",
      "20/20 [==============================] - 0s 789us/step\n",
      "[[0.1883396344245913, 0.8116603655754087], [0.2156642614953903, 0.7843357385046097], [0.6214721999744693, 0.37852780002553055], [0.17725784599677727, 0.8227421540032227], [0.3484395360455407, 0.6515604639544593], [0.16923572306215642, 0.8307642769378436], [0.04128684494913536, 0.9587131550508646], [0.0070181938520651466, 0.992981806147935], [0.0827464157991859, 0.9172535842008143], [0.017035549708432095, 0.982964450291568], [0.6003772771438632, 0.39962272285613676], [0.45456380760258297, 0.5454361923974169], [0.27735244418923855, 0.7226475558107613], [0.6347354510007818, 0.36526454899921834], [0.5604084801825945, 0.4395915198174055], [0.4617017936443861, 0.5382982063556138], [0.23217001095711728, 0.7678299890428828], [0.39007372409192337, 0.6099262759080766], [0.2285178357769357, 0.7714821642230643], [0.28908472736674207, 0.7109152726332579], [0.6576677918519088, 0.34233220814809107], [0.04500353474094825, 0.9549964652590517], [0.06344468538314461, 0.9365553146168554], [0.4476378309304264, 0.5523621690695736], [0.4079548316308367, 0.5920451683691633], [0.4813438434401648, 0.5186561565598351], [0.27701892634418884, 0.7229810736558111], [0.45971772431711033, 0.5402822756828896], [0.6049817698770811, 0.3950182301229189], [0.5901361909860596, 0.40986380901394037], [0.36710615054133633, 0.6328938494586636], [0.34207491643199117, 0.6579250835680087], [0.32696597802793437, 0.6730340219720656], [0.639715752431213, 0.36028424756878685], [0.506748838954985, 0.4932511610450149], [0.05598936860327725, 0.9440106313967227], [0.051628101299343344, 0.9483718987006566], [0.031261630823403073, 0.968738369176597], [0.02432948009074556, 0.9756705199092545], [0.04329561895845543, 0.9567043810415445], [0.4669998688450137, 0.5330001311549863], [0.1857479407942809, 0.814252059205719], [0.3319947587202114, 0.6680052412797887], [0.5191499036313618, 0.48085009636863807], [0.7019738052887411, 0.2980261947112589], [0.16059359857314015, 0.8394064014268598], [0.2511539832732156, 0.7488460167267845], [0.14547771578521557, 0.8545222842147845], [0.22493519799986644, 0.7750648020001336], [0.44047671207181904, 0.5595232879281808], [0.4479351360919886, 0.5520648639080113], [0.419602212376593, 0.580397787623407], [0.42839862234513537, 0.5716013776548645], [0.6369561393992447, 0.36304386060075533], [0.4003486178898222, 0.5996513821101779], [0.5159330649313668, 0.4840669350686332], [0.2629921897460126, 0.7370078102539873], [0.7012488980330569, 0.2987511019669432], [0.5481950109749679, 0.4518049890250321], [0.47965128266778867, 0.5203487173322112]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.75%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2572 - val_loss: -0.7922\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8367 - val_loss: -0.8903\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8996 - val_loss: -0.8991\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9049 - val_loss: -0.8997\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9052 - val_loss: -0.8999\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9055 - val_loss: -0.9001\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9057 - val_loss: -0.9003\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9058 - val_loss: -0.9004\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9059 - val_loss: -0.9006\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9008\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9063 - val_loss: -0.9011\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9014\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9068 - val_loss: -0.9016\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9071 - val_loss: -0.9019\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9073 - val_loss: -0.9021\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9075 - val_loss: -0.9024\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9078 - val_loss: -0.9026\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9081 - val_loss: -0.9029\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9084 - val_loss: -0.9032\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9086 - val_loss: -0.9034\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9089 - val_loss: -0.9037\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9093 - val_loss: -0.9041\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9098 - val_loss: -0.9046\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9103 - val_loss: -0.9052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9111 - val_loss: -0.9061\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9122 - val_loss: -0.9076\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9138 - val_loss: -0.9095\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9160 - val_loss: -0.9123\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9189 - val_loss: -0.9150\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9214 - val_loss: -0.9172\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9236 - val_loss: -0.9190\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9198\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9261 - val_loss: -0.9206\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9267 - val_loss: -0.9207\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9268 - val_loss: -0.9195\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9268 - val_loss: -0.9185\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9161\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9226 - val_loss: -0.9115\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9227 - val_loss: -0.9128\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9210 - val_loss: -0.9203\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9194\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9202\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9260 - val_loss: -0.9211\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9269 - val_loss: -0.9205\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9267 - val_loss: -0.9200\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9206\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9260 - val_loss: -0.9184\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9258 - val_loss: -0.9169\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9196\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9269 - val_loss: -0.9193\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 758us/step\n",
      "20/20 [==============================] - 0s 889us/step\n",
      "[[0.3451747158505822, 0.6548252841494178], [0.30234843483425317, 0.6976515651657467], [0.38825979686999884, 0.6117402031300012], [0.11381357096630758, 0.8861864290336925], [0.5189583774981561, 0.481041622501844], [0.5352153641724475, 0.46478463582755236], [0.47638508349235714, 0.5236149165076429], [0.3851490022057472, 0.6148509977942529], [0.5100807025471689, 0.489919297452831], [0.7514384490141723, 0.24856155098582758], [0.3683650279469869, 0.631634972053013], [0.8691359893085677, 0.13086401069143236], [0.45367558163864696, 0.546324418361353], [0.542577076250804, 0.457422923749196], [0.5487263545106309, 0.4512736454893692], [0.22095290187220906, 0.7790470981277908], [0.14891484373074576, 0.8510851562692543], [0.21475522981581177, 0.7852447701841883], [0.07057198316434458, 0.9294280168356555], [0.15941409806964305, 0.840585901930357], [0.06015556285527135, 0.9398444371447285], [0.043866955285829234, 0.9561330447141707], [0.16321904203341298, 0.836780957966587], [0.07589362017455391, 0.9241063798254461], [0.5320821749860306, 0.4679178250139693], [0.443865585165191, 0.5561344148348091], [0.5237357511351581, 0.47626424886484187], [0.38632077086367256, 0.6136792291363273], [0.6882302137601565, 0.3117697862398435], [0.8632733059041557, 0.13672669409584443], [0.32957768448700275, 0.6704223155129972], [0.265063048319224, 0.734936951680776], [0.6584295098999123, 0.3415704901000878], [0.19049691588398346, 0.8095030841160165], [0.19425842345221433, 0.8057415765477858], [0.2455626604322344, 0.7544373395677657], [0.10884425611077808, 0.8911557438892217], [0.41481315733040636, 0.5851868426695935], [0.30205730626791283, 0.6979426937320872], [0.05845769016052391, 0.9415423098394761], [0.42549662471975624, 0.5745033752802438], [0.820854579180093, 0.17914542081990703], [0.5691709282641069, 0.43082907173589313], [0.35895086825781986, 0.6410491317421801], [0.29956508570051243, 0.7004349142994875], [0.22912762194397998, 0.77087237805602], [0.6096643414595277, 0.39033565854047214], [0.5454944712022634, 0.45450552879773665], [0.7859052786963483, 0.2140947213036518], [0.5145553293866549, 0.48544467061334506], [0.345491929639875, 0.6545080703601249], [0.3022057155116596, 0.6977942844883404], [0.40420478098137863, 0.5957952190186215], [0.2754244576351378, 0.7245755423648623], [0.34167899435913296, 0.6583210056408673], [0.46154033439465647, 0.5384596656053435], [0.75293810381307, 0.24706189618693], [0.34137349606829226, 0.6586265039317076], [0.644164960766114, 0.35583503923388604], [0.4409637996485454, 0.5590362003514546]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.6666666666666666%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.1940 - val_loss: -0.7691\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8192 - val_loss: -0.8816\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8952 - val_loss: -0.8946\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9034 - val_loss: -0.8955\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.8955\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.8956\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.8958\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9043 - val_loss: -0.8960\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.8963\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9047 - val_loss: -0.8966\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9050 - val_loss: -0.8969\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9053 - val_loss: -0.8972\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9056 - val_loss: -0.8977\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9059 - val_loss: -0.8981\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9063 - val_loss: -0.8987\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9069 - val_loss: -0.8995\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9076 - val_loss: -0.9005\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9085 - val_loss: -0.9019\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9100 - val_loss: -0.9040\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9121 - val_loss: -0.9068\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9144 - val_loss: -0.9104\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9176 - val_loss: -0.9133\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9200 - val_loss: -0.9152\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9214 - val_loss: -0.9171\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9227 - val_loss: -0.9181\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9235 - val_loss: -0.9168\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9235 - val_loss: -0.9183\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9244 - val_loss: -0.9186\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9248 - val_loss: -0.9192\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9249 - val_loss: -0.9197\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9254 - val_loss: -0.9194\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9252 - val_loss: -0.9192\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9252 - val_loss: -0.9191\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9250 - val_loss: -0.9198\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9256 - val_loss: -0.9201\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9261 - val_loss: -0.9204\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9202\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9258 - val_loss: -0.9203\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9261 - val_loss: -0.9198\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9253 - val_loss: -0.9203\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9258 - val_loss: -0.9197\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9188\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9200\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9194\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9247 - val_loss: -0.9183\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9240 - val_loss: -0.9159\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9220 - val_loss: -0.9193\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9245 - val_loss: -0.9155\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9174\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9199\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 891us/step\n",
      "19/19 [==============================] - 0s 872us/step\n",
      "[[0.15956626196333829, 0.8404337380366618], [0.141660719855903, 0.858339280144097], [0.0999217629839026, 0.9000782370160973], [0.2950428383319038, 0.7049571616680962], [0.11892479617583147, 0.8810752038241685], [0.2800313419931196, 0.7199686580068805], [0.14619859523991086, 0.8538014047600891], [0.1799483084440582, 0.8200516915559418], [0.1719597987497951, 0.8280402012502049], [0.18278555889488962, 0.8172144411051105], [0.5716090852302538, 0.42839091476974633], [0.5854524676622721, 0.4145475323377279], [0.7750861854302223, 0.22491381456977777], [0.540594824021311, 0.45940517597868913], [0.3391652420314225, 0.6608347579685774], [0.37712328510843646, 0.6228767148915636], [0.4648676521216437, 0.5351323478783561], [0.7204266089701643, 0.2795733910298357], [0.37481862275050787, 0.6251813772494921], [0.23507862773310775, 0.7649213722668922], [0.637898861445189, 0.362101138554811], [0.5381880354459754, 0.4618119645540245], [0.5391319151565284, 0.4608680848434715], [0.5060351299683136, 0.49396487003168654], [0.5120847259775236, 0.4879152740224763], [0.6355517454966763, 0.3644482545033236], [0.324385858394554, 0.675614141605446], [0.43548769253771524, 0.5645123074622848], [0.6414860132067198, 0.3585139867932801], [0.6767225625581902, 0.3232774374418098], [0.6176035566358509, 0.38239644336414924], [0.14141438862134248, 0.8585856113786574], [0.1607469138097569, 0.8392530861902432], [0.37625445631533483, 0.6237455436846653], [0.4719920242220129, 0.5280079757779871], [0.45882368824216924, 0.5411763117578308], [0.2551294676947573, 0.7448705323052427], [0.3755825636339878, 0.6244174363660122], [0.184585286764807, 0.815414713235193], [0.4648024369526829, 0.5351975630473171], [0.5755946195189228, 0.42440538048107723], [0.3674024974668041, 0.6325975025331959], [0.7700944484507779, 0.22990555154922226], [0.2821076232645286, 0.7178923767354715], [0.7163371214002586, 0.2836628785997414], [0.2015843955050775, 0.7984156044949224], [0.43711760635882646, 0.5628823936411735], [0.42400286661238906, 0.575997133387611], [0.24720660592871507, 0.7527933940712848], [0.3943456924047363, 0.6056543075952637], [0.039390735157392345, 0.9606092648426077], [0.026431962003101283, 0.9735680379968985], [0.122056014818071, 0.8779439851819291], [0.03960514318131121, 0.9603948568186886], [0.08075428111999346, 0.9192457188800066], [0.6196583151232928, 0.38034168487670716], [0.6038750117161398, 0.3961249882838601], [0.6406709046643676, 0.3593290953356323], [0.5990003951261187, 0.4009996048738813], [0.4575417068765417, 0.5424582931234583], [0.19223571742216725, 0.8077642825778327], [0.32664736044672343, 0.6733526395532766], [0.14316036113976774, 0.8568396388602322], [0.595432066429403, 0.40456793357059695], [0.29416136318825764, 0.7058386368117424], [0.5793612138444839, 0.4206387861555161], [0.31872378122349954, 0.6812762187765005], [0.2486651369280199, 0.75133486307198], [0.18699383196570193, 0.8130061680342981], [0.4434137150044306, 0.5565862849955694], [0.49900176590287326, 0.5009982340971266], [0.45656034492723235, 0.5434396550727676], [0.706032074024031, 0.29396792597596905], [0.5200041610693431, 0.47999583893065684], [0.4591408358088136, 0.5408591641911862]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.76%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2068 - val_loss: -0.7683\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8134 - val_loss: -0.8906\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8941 - val_loss: -0.9037\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9019 - val_loss: -0.9044\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9021 - val_loss: -0.9044\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9021 - val_loss: -0.9046\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9022 - val_loss: -0.9047\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9024 - val_loss: -0.9049\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9025 - val_loss: -0.9050\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9027 - val_loss: -0.9052\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9029 - val_loss: -0.9053\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9031 - val_loss: -0.9055\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9034 - val_loss: -0.9057\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9036 - val_loss: -0.9059\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9040 - val_loss: -0.9062\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9043 - val_loss: -0.9066\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9048 - val_loss: -0.9070\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9052 - val_loss: -0.9075\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9059 - val_loss: -0.9082\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9068 - val_loss: -0.9092\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.9105\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9096 - val_loss: -0.9121\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9117 - val_loss: -0.9141\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9140 - val_loss: -0.9161\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9165 - val_loss: -0.9179\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9185 - val_loss: -0.9193\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9201 - val_loss: -0.9202\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9211 - val_loss: -0.9209\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9216 - val_loss: -0.9215\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9222 - val_loss: -0.9209\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9224 - val_loss: -0.9219\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9233 - val_loss: -0.9226\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9236 - val_loss: -0.9223\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9234 - val_loss: -0.9207\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9220 - val_loss: -0.9187\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9206 - val_loss: -0.9170\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9210 - val_loss: -0.9220\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9217 - val_loss: -0.9202\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9217 - val_loss: -0.9195\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9195 - val_loss: -0.9188\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9206 - val_loss: -0.9234\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9224 - val_loss: -0.9201\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9218 - val_loss: -0.9214\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9238 - val_loss: -0.9226\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9243 - val_loss: -0.9228\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9239 - val_loss: -0.9229\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9246 - val_loss: -0.9230\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9234 - val_loss: -0.9189\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: -0.9215 - val_loss: -0.9201\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9212 - val_loss: -0.9181\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 764us/step\n",
      "19/19 [==============================] - 0s 802us/step\n",
      "[[0.3546240354843718, 0.6453759645156283], [0.563340483743759, 0.436659516256241], [0.2975049175974663, 0.7024950824025337], [0.29811906272752237, 0.7018809372724777], [0.1753701322584118, 0.8246298677415882], [0.1469962332352638, 0.8530037667647361], [0.36621438648586935, 0.6337856135141308], [0.25273092819427767, 0.7472690718057224], [0.29919933739851945, 0.7008006626014807], [0.2324529167886456, 0.7675470832113543], [0.37691713407179894, 0.6230828659282011], [0.5040458651147646, 0.4959541348852354], [0.2633246569434444, 0.7366753430565556], [0.4352101699548452, 0.564789830045155], [0.18281884716042818, 0.8171811528395718], [0.36937832701369167, 0.6306216729863086], [0.3385672020090996, 0.6614327979909004], [0.424629334007971, 0.575370665992029], [0.13138181020456524, 0.8686181897954348], [0.2306979842856552, 0.7693020157143449], [0.03716612370822525, 0.9628338762917747], [0.04090198057306332, 0.9590980194269367], [0.03859997996267058, 0.9614000200373294], [0.03433104708905455, 0.9656689529109455], [0.029214287473288195, 0.9707857125267119], [0.509829739974658, 0.49017026002534214], [0.6985296260992772, 0.30147037390072284], [0.6948451175918704, 0.30515488240812955], [0.47999877196936386, 0.5200012280306361], [0.5378603715703455, 0.4621396284296545], [0.196732799120995, 0.8032672008790049], [0.503078046364146, 0.4969219536358539], [0.4975389316225547, 0.5024610683774451], [0.37033237661713914, 0.6296676233828609], [0.236280910758387, 0.763719089241613], [0.17092313288717795, 0.8290768671128221], [0.09183483118010578, 0.9081651688198942], [0.04292399941464946, 0.9570760005853506], [0.05278165096306558, 0.9472183490369345], [0.06705556976752644, 0.9329444302324734], [0.4782096695993017, 0.5217903304006983], [0.38966035283422584, 0.6103396471657742], [0.34766239479192, 0.65233760520808], [0.5734615320779016, 0.42653846792209843], [0.6659812870939776, 0.33401871290602236], [0.3614170735273432, 0.6385829264726566], [0.28783453800664693, 0.712165461993353], [0.19538582648234004, 0.8046141735176601], [0.2557848033449672, 0.7442151966550328], [0.184346536349727, 0.8156534636502731], [0.3148782786315797, 0.6851217213684203], [0.3014684636023327, 0.6985315363976672], [0.20228565437219914, 0.7977143456278009], [0.19373748730662868, 0.8062625126933715], [0.14940936783773803, 0.850590632162262], [0.5547795421844782, 0.4452204578155219], [0.19297874450999644, 0.8070212554900034], [0.3667419025912342, 0.6332580974087659], [0.42177152241356275, 0.5782284775864373], [0.19770106349166622, 0.8022989365083337], [0.22887695873823855, 0.7711230412617616], [0.21292593968296641, 0.7870740603170336], [0.16823279352489845, 0.8317672064751016], [0.4314708128933989, 0.5685291871066012], [0.44582720804556486, 0.554172791954435], [0.34861105826843, 0.6513889417315699], [0.47825736211795494, 0.5217426378820451], [0.2719891694291004, 0.7280108305708995], [0.5269124358410923, 0.47308756415890774], [0.38806551552163226, 0.6119344844783677], [0.4276749099411913, 0.5723250900588088], [0.2159880035368023, 0.7840119964631977], [0.46729157780088115, 0.5327084221991187], [0.502571939791122, 0.497428060208878], [0.4196384507007962, 0.5803615492992038]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7466666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2256 - val_loss: -0.7850\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8275 - val_loss: -0.8921\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.8981 - val_loss: -0.9025\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9046 - val_loss: -0.9030\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9049 - val_loss: -0.9032\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9050 - val_loss: -0.9035\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9053 - val_loss: -0.9038\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9055 - val_loss: -0.9040\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9058 - val_loss: -0.9042\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9043\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9063 - val_loss: -0.9045\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9046\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9069 - val_loss: -0.9048\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9072 - val_loss: -0.9050\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9076 - val_loss: -0.9052\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.9054\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9084 - val_loss: -0.9058\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9089 - val_loss: -0.9061\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9095 - val_loss: -0.9065\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9104 - val_loss: -0.9073\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9116 - val_loss: -0.9082\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9132 - val_loss: -0.9098\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: -0.9154 - val_loss: -0.9115\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9179 - val_loss: -0.9138\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9207 - val_loss: -0.9158\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9176\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9249 - val_loss: -0.9175\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9172\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9237 - val_loss: -0.9153\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9157\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9189\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9260 - val_loss: -0.9199\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9270 - val_loss: -0.9192\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9204\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9273 - val_loss: -0.9202\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9274 - val_loss: -0.9198\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9278 - val_loss: -0.9204\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9282 - val_loss: -0.9203\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9266 - val_loss: -0.9164\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9246 - val_loss: -0.9189\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9196\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9257 - val_loss: -0.9191\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9267 - val_loss: -0.9193\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9272 - val_loss: -0.9172\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9249 - val_loss: -0.9193\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9264 - val_loss: -0.9196\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9193\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9269 - val_loss: -0.9186\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9191\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9264 - val_loss: -0.9177\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 825us/step\n",
      "19/19 [==============================] - 0s 822us/step\n",
      "[[0.20552276846155101, 0.794477231538449], [0.2580532559856927, 0.7419467440143073], [0.5890968497049482, 0.4109031502950518], [0.18326068439384344, 0.8167393156061566], [0.4895342591388937, 0.5104657408611063], [0.5364954831959513, 0.4635045168040488], [0.5912718643932068, 0.4087281356067932], [0.39041910516010325, 0.6095808948398967], [0.5583888927069109, 0.44161110729308906], [0.7094909014388298, 0.2905090985611703], [0.3011726469324746, 0.6988273530675255], [0.8210212435341255, 0.17897875646587455], [0.5364297896309094, 0.4635702103690905], [0.3256827296124283, 0.6743172703875717], [0.5437333240591015, 0.4562666759408985], [0.0929933093268861, 0.9070066906731139], [0.16058485282179216, 0.8394151471782079], [0.16238560357208762, 0.8376143964279124], [0.18909159416516863, 0.8109084058348314], [0.07633119487273587, 0.923668805127264], [0.011996495806183699, 0.9880035041938164], [0.006506010839429625, 0.9934939891605703], [0.007387662702006862, 0.9926123372979931], [0.008054987846723875, 0.991945012153276], [0.660948040705033, 0.3390519592949672], [0.5699224888601309, 0.4300775111398692], [0.7274398551404448, 0.27256014485955504], [0.2678952705483297, 0.7321047294516702], [0.3073289466573387, 0.6926710533426614], [0.6379288284384812, 0.3620711715615188], [0.19350459560254835, 0.8064954043974517], [0.214239202254764, 0.7857607977452361], [0.24195290177598078, 0.7580470982240193], [0.09587575715771349, 0.9041242428422864], [0.18780356291160114, 0.812196437088399], [0.1325057514263372, 0.8674942485736629], [0.02719743683129308, 0.972802563168707], [0.11911555405261001, 0.8808844459473899], [0.05393291859642452, 0.9460670814035754], [0.33620369732967637, 0.6637963026703237], [0.4178989849283391, 0.582101015071661], [0.6483418526355005, 0.3516581473644995], [0.40822101810446876, 0.5917789818955312], [0.6266531647354985, 0.37334683526450163], [0.7517910556250815, 0.24820894437491836], [0.3695946542777555, 0.6304053457222444], [0.3078220574148112, 0.6921779425851887], [0.2737628229474627, 0.7262371770525375], [0.4556649294053462, 0.5443350705946537], [0.23631386300574705, 0.7636861369942529], [0.07114321744228565, 0.9288567825577143], [0.024633686301273588, 0.9753663136987263], [0.0023537717384351045, 0.9976462282615648], [0.022083062140071653, 0.9779169378599284], [0.04711646176803382, 0.9528835382319661], [0.5212281772881994, 0.4787718227118006], [0.43940066952371726, 0.5605993304762827], [0.41433578751922717, 0.5856642124807729], [0.5800308023503162, 0.41996919764968366], [0.8043071589275194, 0.1956928410724807], [0.29625524970424766, 0.7037447502957523], [0.42448749513274475, 0.5755125048672554], [0.47625242317322325, 0.5237475768267768], [0.6442555893428392, 0.35574441065716067], [0.5467150183535716, 0.45328498164642844], [0.20119934291064095, 0.7988006570893589], [0.19648375042202054, 0.8035162495779794], [0.3009344772323539, 0.6990655227676461], [0.26356409220284427, 0.7364359077971556], [0.5914060850614073, 0.4085939149385927], [0.3923158922851159, 0.607684107714884], [0.5297636398330217, 0.47023636016697823], [0.42568216179015184, 0.5743178382098482], [0.5952080531874504, 0.4047919468125496], [0.4386310182620577, 0.5613689817379423]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7333333333333333%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.2289 - val_loss: -0.7973\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8341 - val_loss: -0.8924\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.8965 - val_loss: -0.9007\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9016 - val_loss: -0.9009\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9017 - val_loss: -0.9009\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9011\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9019 - val_loss: -0.9013\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: -0.9021 - val_loss: -0.9015\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9023 - val_loss: -0.9017\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9025 - val_loss: -0.9020\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9028 - val_loss: -0.9023\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9031 - val_loss: -0.9026\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9035 - val_loss: -0.9031\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9036\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9049 - val_loss: -0.9042\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9055 - val_loss: -0.9050\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9067 - val_loss: -0.9061\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9082 - val_loss: -0.9075\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9102 - val_loss: -0.9093\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9127 - val_loss: -0.9117\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9155 - val_loss: -0.9136\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9181 - val_loss: -0.9152\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9201 - val_loss: -0.9165\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9215 - val_loss: -0.9169\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9226 - val_loss: -0.9180\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9233 - val_loss: -0.9181\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9236 - val_loss: -0.9186\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9180\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9240 - val_loss: -0.9190\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9245 - val_loss: -0.9189\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9246 - val_loss: -0.9192\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9250 - val_loss: -0.9186\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9249 - val_loss: -0.9186\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9247 - val_loss: -0.9173\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9172\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9209 - val_loss: -0.9080\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9198 - val_loss: -0.9155\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9216 - val_loss: -0.9136\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9226 - val_loss: -0.9159\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9230 - val_loss: -0.9174\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9190\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9188\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9247 - val_loss: -0.9194\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9247 - val_loss: -0.9186\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9248 - val_loss: -0.9197\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9252 - val_loss: -0.9192\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9252 - val_loss: -0.9189\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9253 - val_loss: -0.9193\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9255 - val_loss: -0.9195\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9196\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 851us/step\n",
      "19/19 [==============================] - 0s 869us/step\n",
      "[[0.35849944775222553, 0.6415005522477744], [0.1821030564453423, 0.8178969435546577], [0.18728425854889422, 0.8127157414511059], [0.4169462874875971, 0.5830537125124029], [0.2945274851995219, 0.7054725148004782], [0.031360795109425285, 0.9686392048905748], [0.04031153688254647, 0.9596884631174535], [0.06472699627376986, 0.9352730037262302], [0.11033737527639952, 0.8896626247236005], [0.06682403236213422, 0.9331759676378657], [0.38280014754720115, 0.6171998524527988], [0.30390570758998975, 0.6960942924100102], [0.45565777994739487, 0.5443422200526051], [0.34364619797263024, 0.6563538020273696], [0.5203147153319878, 0.47968528466801225], [0.4918259690482484, 0.5081740309517516], [0.3161073585791886, 0.6838926414208114], [0.24241588153329166, 0.7575841184667085], [0.30874467138428363, 0.6912553286157164], [0.528495419789962, 0.47150458021003805], [0.2564119047561506, 0.7435880952438494], [0.4165467378614697, 0.5834532621385304], [0.4493588540778577, 0.5506411459221423], [0.28284522389374667, 0.7171547761062536], [0.19747247173724505, 0.8025275282627549], [0.33095004744084455, 0.6690499525591556], [0.45405381145054835, 0.5459461885494515], [0.6113166788955136, 0.38868332110448645], [0.4968245108137669, 0.5031754891862332], [0.5681540165646561, 0.4318459834353439], [0.4703698895073761, 0.5296301104926238], [0.30460404751440784, 0.6953959524855922], [0.39359404915197904, 0.606405950848021], [0.2781632100558602, 0.7218367899441398], [0.34717917096427675, 0.6528208290357234], [0.6779812330023893, 0.3220187669976106], [0.3291862027129683, 0.6708137972870318], [0.3826069245017684, 0.6173930754982315], [0.3651286226117098, 0.6348713773882901], [0.6130761662193152, 0.3869238337806848], [0.5310992960263807, 0.46890070397361927], [0.5183851085466169, 0.4816148914533831], [0.3262392338857235, 0.6737607661142766], [0.31533082172603466, 0.6846691782739653], [0.43312191081881224, 0.5668780891811875], [0.33736176407539314, 0.662638235924607], [0.43035965803691245, 0.5696403419630877], [0.42304663521498687, 0.5769533647850131], [0.1970177523705012, 0.802982247629499], [0.5256398003266509, 0.4743601996733491], [0.11766323394610163, 0.8823367660538985], [0.06506570254735013, 0.93493429745265], [0.05669607866978528, 0.9433039213302147], [0.0685785339340827, 0.9314214660659172], [0.03848814092047232, 0.9615118590795277], [0.5987950351080049, 0.4012049648919951], [0.44315440155730534, 0.5568455984426945], [0.44041019534553016, 0.5595898046544701], [0.5889913450917741, 0.41100865490822597], [0.6693822688106439, 0.3306177311893562], [0.36901947401320023, 0.6309805259867998], [0.14666028856304147, 0.8533397114369585], [0.1826123542320613, 0.8173876457679387], [0.17727816833912563, 0.8227218316608744], [0.36146435164382473, 0.6385356483561754], [0.29962945773587124, 0.7003705422641288], [0.3193155124981971, 0.680684487501803], [0.0666663033846142, 0.9333336966153858], [0.33366245211596346, 0.6663375478840367], [0.41089236014686353, 0.5891076398531365], [0.44333027715219125, 0.5566697228478088], [0.5738195386544034, 0.4261804613455965], [0.4790950528771447, 0.5209049471228553], [0.5770387939380119, 0.42296120606198806], [0.4314540911912611, 0.5685459088087389]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7466666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.1992 - val_loss: -0.7747\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8190 - val_loss: -0.8894\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8946 - val_loss: -0.9006\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9014 - val_loss: -0.9012\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9018 - val_loss: -0.9013\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9018 - val_loss: -0.9014\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9020 - val_loss: -0.9015\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9021 - val_loss: -0.9017\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9022 - val_loss: -0.9018\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9024 - val_loss: -0.9019\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9025 - val_loss: -0.9021\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9026 - val_loss: -0.9022\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9028 - val_loss: -0.9024\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9029 - val_loss: -0.9026\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9031 - val_loss: -0.9028\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9033 - val_loss: -0.9030\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9034 - val_loss: -0.9032\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9036 - val_loss: -0.9034\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9037 - val_loss: -0.9036\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.9038\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9041 - val_loss: -0.9040\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9043 - val_loss: -0.9043\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9046\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9048 - val_loss: -0.9050\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9052 - val_loss: -0.9055\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9056 - val_loss: -0.9062\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9062 - val_loss: -0.9070\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9070 - val_loss: -0.9083\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9082 - val_loss: -0.9101\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9097 - val_loss: -0.9120\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9119 - val_loss: -0.9158\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9151 - val_loss: -0.9182\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9169 - val_loss: -0.9198\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9181 - val_loss: -0.9203\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9192 - val_loss: -0.9204\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9189 - val_loss: -0.9215\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9202 - val_loss: -0.9229\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9212 - val_loss: -0.9234\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9208 - val_loss: -0.9226\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9201 - val_loss: -0.9189\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9188 - val_loss: -0.9241\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9210 - val_loss: -0.9235\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9212 - val_loss: -0.9232\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9211 - val_loss: -0.9238\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9220 - val_loss: -0.9238\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9219 - val_loss: -0.9202\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9213 - val_loss: -0.9128\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9136 - val_loss: -0.9235\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9194 - val_loss: -0.9195\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9180 - val_loss: -0.9227\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 793us/step\n",
      "19/19 [==============================] - 0s 837us/step\n",
      "[[0.4384382784499383, 0.5615617215500618], [0.1273475423218767, 0.8726524576781233], [0.3498291815851091, 0.650170818414891], [0.5955863342659199, 0.40441366573408005], [0.17147983505573283, 0.8285201649442671], [0.18801568225904194, 0.8119843177409581], [0.38170430847295944, 0.6182956915270406], [0.11692531667383695, 0.8830746833261631], [0.031482019927308875, 0.9685179800726911], [0.03159385899284783, 0.9684061410071523], [0.3708232395657599, 0.6291767604342402], [0.6037539316742169, 0.39624606832578313], [0.5656318393421964, 0.4343681606578036], [0.5523703921102374, 0.4476296078897627], [0.6167740562329828, 0.38322594376701713], [0.4101255462285923, 0.5898744537714076], [0.1379579245172516, 0.8620420754827484], [0.1545705824736217, 0.8454294175263783], [0.1500976781595445, 0.8499023218404556], [0.6751889492247278, 0.32481105077527217], [0.03531892636488314, 0.9646810736351168], [0.025683245045840228, 0.9743167549541598], [0.014399905377896621, 0.9856000946221034], [0.011457127844769082, 0.9885428721552308], [0.014751116217032496, 0.9852488837829674], [0.7231754854784024, 0.2768245145215977], [0.5846491680058653, 0.4153508319941347], [0.5645949673298803, 0.43540503267011965], [0.5783601190367034, 0.4216398809632967], [0.7039269774212367, 0.29607302257876333], [0.2726992003859125, 0.7273007996140874], [0.6160904902263854, 0.3839095097736146], [0.09379010039010537, 0.9062098996098946], [0.4088350951230365, 0.5911649048769636], [0.13649937987242722, 0.8635006201275728], [0.06892360693170962, 0.9310763930682903], [0.11891207407722815, 0.881087925922772], [0.12227725914474594, 0.8777227408552541], [0.10768467442816457, 0.8923153255718355], [0.2569136848919138, 0.7430863151080862], [0.7578422851794954, 0.24215771482050466], [0.5814498256860632, 0.4185501743139368], [0.5471926821415354, 0.4528073178584646], [0.6490254447928712, 0.35097455520712884], [0.5942669830096073, 0.40573301699039277], [0.12169822881893767, 0.8783017711810623], [0.23972943701879823, 0.7602705629812017], [0.6918829301095755, 0.30811706989042453], [0.1666026116820036, 0.8333973883179964], [0.17132335687531802, 0.828676643124682], [0.1778381481076609, 0.822161851892339], [0.09126264345193713, 0.9087373565480628], [0.4495596743711739, 0.5504403256288262], [0.49952971771845717, 0.5004702822815429], [0.10824308026398886, 0.8917569197360111], [0.4410697818790331, 0.558930218120967], [0.5342596160405672, 0.4657403839594328], [0.36252238648739465, 0.6374776135126052], [0.2495439052171575, 0.7504560947828425], [0.5186615927267482, 0.48133840727325194], [0.17160217212414208, 0.8283978278758579], [0.1586119590742521, 0.8413880409257479], [0.1385680706606442, 0.8614319293393558], [0.1241256568452372, 0.8758743431547629], [0.09208335942700598, 0.9079166405729939], [0.29510334134333693, 0.7048966586566631], [0.517664004522743, 0.48233599547725703], [0.2978042702288659, 0.7021957297711341], [0.47276355028795203, 0.5272364497120479], [0.2839465659264536, 0.7160534340735463], [0.254491908116467, 0.7455080918835331], [0.49505786054229634, 0.5049421394577036], [0.440106010983771, 0.5598939890162289], [0.4797987406310982, 0.5202012593689018], [0.5515715783841898, 0.4484284216158102]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8266666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2292 - val_loss: -0.7837\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8346 - val_loss: -0.8858\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9008 - val_loss: -0.8955\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9069 - val_loss: -0.8961\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9072 - val_loss: -0.8963\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9074 - val_loss: -0.8965\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9076 - val_loss: -0.8966\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9077 - val_loss: -0.8968\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.8969\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9081 - val_loss: -0.8971\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9082 - val_loss: -0.8972\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9084 - val_loss: -0.8974\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9086 - val_loss: -0.8975\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9088 - val_loss: -0.8977\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9090 - val_loss: -0.8978\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9092 - val_loss: -0.8980\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9094 - val_loss: -0.8981\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9096 - val_loss: -0.8983\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9098 - val_loss: -0.8985\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9100 - val_loss: -0.8987\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9102 - val_loss: -0.8989\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9105 - val_loss: -0.8991\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9108 - val_loss: -0.8994\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9112 - val_loss: -0.8999\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9117 - val_loss: -0.9005\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9124 - val_loss: -0.9011\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9132 - val_loss: -0.9022\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9146 - val_loss: -0.9040\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9164 - val_loss: -0.9062\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9188 - val_loss: -0.9090\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9215 - val_loss: -0.9116\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9237 - val_loss: -0.9136\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9255 - val_loss: -0.9146\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9262 - val_loss: -0.9157\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9269 - val_loss: -0.9161\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9273 - val_loss: -0.9166\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9274 - val_loss: -0.9149\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9161\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9154\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9272 - val_loss: -0.9164\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9282 - val_loss: -0.9171\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9123\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9243 - val_loss: -0.9170\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9174\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9270 - val_loss: -0.9158\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9269 - val_loss: -0.9161\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9278 - val_loss: -0.9157\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9164\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9277 - val_loss: -0.9150\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9264 - val_loss: -0.9177\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 755us/step\n",
      "20/20 [==============================] - 0s 824us/step\n",
      "[[0.5017339873374458, 0.4982660126625541], [0.5070010589049523, 0.4929989410950479], [0.17588720382997614, 0.824112796170024], [0.14725798690397504, 0.8527420130960249], [0.15360223856906802, 0.846397761430932], [0.15879952468842018, 0.8412004753115798], [0.09390106567793682, 0.9060989343220631], [0.16032461447710128, 0.8396753855228988], [0.19222601978289983, 0.8077739802171001], [0.18797757786732716, 0.8120224221326728], [0.33368490680590973, 0.6663150931940902], [0.6427200407295814, 0.35727995927041845], [0.5221859175064076, 0.4778140824935925], [0.3853032689070496, 0.6146967310929505], [0.7130632249508502, 0.2869367750491498], [0.23539610124827443, 0.7646038987517255], [0.27885802207405386, 0.721141977925946], [0.3558859156510743, 0.6441140843489257], [0.4258088259841767, 0.5741911740158234], [0.5116563251659907, 0.4883436748340092], [0.1325196768156825, 0.8674803231843173], [0.008544459664076551, 0.9914555403359235], [0.005902991424736101, 0.9940970085752638], [0.005655673837380559, 0.9943443261626195], [0.00451810162008476, 0.9954818983799152], [0.7120997277174215, 0.28790027228257853], [0.6007826923699495, 0.3992173076300505], [0.6155106959779193, 0.3844893040220807], [0.6027211699842824, 0.3972788300157175], [0.4559066416613248, 0.5440933583386752], [0.3640326543118891, 0.635967345688111], [0.5500982786865942, 0.4499017213134057], [0.6072233495746511, 0.3927766504253489], [0.312271137142921, 0.6877288628570791], [0.4663900925846832, 0.5336099074153169], [0.3617658560746988, 0.6382341439253012], [0.18186591896353244, 0.8181340810364675], [0.10950755758014917, 0.8904924424198508], [0.5859183392670284, 0.4140816607329715], [0.5760668963824965, 0.4239331036175034], [0.38283123190548296, 0.617168768094517], [0.3838887002516062, 0.6161112997483937], [0.47622834005808434, 0.5237716599419158], [0.6514910030297075, 0.3485089969702924], [0.5078888739725271, 0.49211112602747287], [0.217214591790571, 0.782785408209429], [0.14828772749760036, 0.8517122725023996], [0.22376085382238697, 0.776239146177613], [0.44968203528661954, 0.5503179647133805], [0.20144409420310955, 0.7985559057968905], [0.009284669357036734, 0.9907153306429631], [0.03559979548600484, 0.9644002045139952], [0.018914109614505254, 0.9810858903854947], [0.015058579237490034, 0.98494142076251], [0.036523106046007586, 0.9634768939539925], [0.33699761629581015, 0.6630023837041898], [0.5227157491461086, 0.4772842508538915], [0.17209551120025093, 0.8279044887997491], [0.6774232573117266, 0.3225767426882734], [0.5449653680623355, 0.4550346319376646]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.75%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: -0.2122 - val_loss: -0.7561\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8164 - val_loss: -0.8785\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8987 - val_loss: -0.8925\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9073 - val_loss: -0.8934\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9078 - val_loss: -0.8935\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9079 - val_loss: -0.8937\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9081 - val_loss: -0.8938\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9083 - val_loss: -0.8940\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9085 - val_loss: -0.8942\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9086 - val_loss: -0.8943\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9088 - val_loss: -0.8945\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9090 - val_loss: -0.8947\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9092 - val_loss: -0.8949\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9094 - val_loss: -0.8952\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9096 - val_loss: -0.8954\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9099 - val_loss: -0.8957\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9101 - val_loss: -0.8961\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9104 - val_loss: -0.8965\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9109 - val_loss: -0.8970\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9114 - val_loss: -0.8977\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9121 - val_loss: -0.8987\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9130 - val_loss: -0.9000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9142 - val_loss: -0.9021\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9162 - val_loss: -0.9049\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9184 - val_loss: -0.9079\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9209 - val_loss: -0.9106\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9127\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9246 - val_loss: -0.9132\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9133\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9253 - val_loss: -0.9160\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9269 - val_loss: -0.9167\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9276 - val_loss: -0.9158\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9265 - val_loss: -0.9172\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9277 - val_loss: -0.9175\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9280 - val_loss: -0.9160\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9273 - val_loss: -0.9171\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9268 - val_loss: -0.9147\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9249 - val_loss: -0.9140\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9265 - val_loss: -0.9128\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9147\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9270 - val_loss: -0.9173\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9283 - val_loss: -0.9162\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9143\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9266 - val_loss: -0.9172\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9277 - val_loss: -0.9169\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9171\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9274 - val_loss: -0.9166\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9271 - val_loss: -0.9138\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9146\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9265 - val_loss: -0.9156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 773us/step\n",
      "20/20 [==============================] - 0s 810us/step\n",
      "[[0.14491747980909417, 0.8550825201909058], [0.23619147689892306, 0.7638085231010769], [0.2124487833937191, 0.7875512166062808], [0.12445718944171323, 0.8755428105582868], [0.21614626662061948, 0.7838537333793805], [0.1538920783155352, 0.8461079216844647], [0.050638219227119155, 0.9493617807728809], [0.38378458820185835, 0.6162154117981415], [0.20482687708650282, 0.7951731229134971], [0.25941029474948596, 0.7405897052505142], [0.4784858210718834, 0.5215141789281165], [0.8237512706400538, 0.17624872935994607], [0.6714947627467719, 0.3285052372532281], [0.5966266872534568, 0.4033733127465432], [0.4670483972014487, 0.5329516027985512], [0.3760667658318749, 0.623933234168125], [0.5027437001913504, 0.4972562998086496], [0.4027429783832207, 0.5972570216167792], [0.29124885908382075, 0.7087511409161791], [0.17740027077879025, 0.8225997292212097], [0.09872157368781632, 0.9012784263121836], [0.13143671889439187, 0.8685632811056082], [0.20311987044108665, 0.7968801295589133], [0.06791490048297115, 0.9320850995170288], [0.08017793729875922, 0.9198220627012408], [0.336447582619735, 0.6635524173802649], [0.5350859908246391, 0.46491400917536074], [0.4941743718075365, 0.5058256281924637], [0.6738017051579674, 0.32619829484203244], [0.368364301128576, 0.631635698871424], [0.3253011776333846, 0.6746988223666155], [0.30296357471202007, 0.6970364252879799], [0.13740270969871102, 0.8625972903012888], [0.2540270727751083, 0.7459729272248916], [0.15833028644657152, 0.8416697135534283], [0.021937976554630704, 0.9780620234453694], [0.00938173852162517, 0.990618261478375], [0.014796208812255893, 0.9852037911877441], [0.3401238472673386, 0.6598761527326615], [0.3245984774439179, 0.6754015225560821], [0.6269932608445161, 0.37300673915548377], [0.36623024748221883, 0.6337697525177812], [0.7305923586247541, 0.2694076413752458], [0.3009130857263526, 0.6990869142736473], [0.7620569010824019, 0.23794309891759813], [0.20292268420362114, 0.797077315796379], [0.252190130907883, 0.7478098690921171], [0.29459013218171637, 0.7054098678182836], [0.5173963688414632, 0.48260363115853655], [0.3871212579546439, 0.6128787420453561], [0.017588690066640326, 0.9824113099333596], [0.014168305520662065, 0.9858316944793377], [0.29344061651575987, 0.7065593834842401], [0.16070056743411293, 0.8392994325658869], [0.13983088512625697, 0.8601691148737431], [0.7233216249395964, 0.2766783750604037], [0.15868701442231958, 0.8413129855776804], [0.45513608031385255, 0.5448639196861476], [0.48512791029458113, 0.5148720897054189], [0.7325120659676991, 0.267487934032301]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2711 - val_loss: -0.7900\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.8439 - val_loss: -0.8848\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9046 - val_loss: -0.8936\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9098 - val_loss: -0.8944\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9103 - val_loss: -0.8947\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9105 - val_loss: -0.8948\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9106 - val_loss: -0.8950\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9108 - val_loss: -0.8951\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9109 - val_loss: -0.8953\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9111 - val_loss: -0.8955\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9113 - val_loss: -0.8958\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9115 - val_loss: -0.8960\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9117 - val_loss: -0.8963\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9119 - val_loss: -0.8966\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9121 - val_loss: -0.8969\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9123 - val_loss: -0.8972\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9126 - val_loss: -0.8975\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9128 - val_loss: -0.8978\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9130 - val_loss: -0.8980\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9132 - val_loss: -0.8982\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9134 - val_loss: -0.8985\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9137 - val_loss: -0.8989\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9139 - val_loss: -0.8996\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9144 - val_loss: -0.9003\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9150 - val_loss: -0.9014\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9159 - val_loss: -0.9027\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9169 - val_loss: -0.9045\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9184 - val_loss: -0.9071\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9205 - val_loss: -0.9097\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9227 - val_loss: -0.9132\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9251 - val_loss: -0.9155\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9267 - val_loss: -0.9170\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9278 - val_loss: -0.9180\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9286 - val_loss: -0.9173\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9285 - val_loss: -0.9192\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9294 - val_loss: -0.9191\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9293 - val_loss: -0.9202\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9298 - val_loss: -0.9198\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9296 - val_loss: -0.9199\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9288 - val_loss: -0.9191\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9291 - val_loss: -0.9205\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9298 - val_loss: -0.9199\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9300 - val_loss: -0.9198\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9299 - val_loss: -0.9197\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9296 - val_loss: -0.9195\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9290 - val_loss: -0.9202\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9295 - val_loss: -0.9177\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9277 - val_loss: -0.9200\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9292 - val_loss: -0.9199\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9288 - val_loss: -0.9169\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 798us/step\n",
      "20/20 [==============================] - 0s 851us/step\n",
      "[[0.4770596905554212, 0.5229403094445789], [0.36335515414211395, 0.6366448458578862], [0.1593469141149264, 0.8406530858850736], [0.18420480278378057, 0.8157951972162192], [0.36129522305140604, 0.6387047769485941], [0.10943466715971925, 0.8905653328402807], [0.14906299694521005, 0.85093700305479], [0.031477843629610695, 0.9685221563703892], [0.037035139760787386, 0.9629648602392127], [0.01151381883780601, 0.988486181162194], [0.5647187452113296, 0.43528125478867036], [0.2557772052551596, 0.7442227947448403], [0.4491267510275101, 0.5508732489724899], [0.5869727258261421, 0.413027274173858], [0.6160585859994699, 0.38394141400053006], [0.32087579525570725, 0.6791242047442927], [0.36645733773545336, 0.6335426622645466], [0.47689174342191837, 0.5231082565780817], [0.31127402953925454, 0.6887259704607456], [0.34788083868226183, 0.6521191613177382], [0.24956735687106113, 0.750432643128939], [0.2504009469880186, 0.7495990530119814], [0.25772854893044583, 0.7422714510695542], [0.32454632496105307, 0.6754536750389468], [0.25452986179701786, 0.745470138202982], [0.49201526098224413, 0.5079847390177558], [0.4492452563842887, 0.5507547436157112], [0.32800942038757797, 0.671990579612422], [0.19508877430421834, 0.8049112256957818], [0.5137958193849039, 0.4862041806150962], [0.2688350039008521, 0.731164996099148], [0.3639483759803318, 0.6360516240196682], [0.19492557290643006, 0.8050744270935699], [0.23576959790929047, 0.7642304020907096], [0.10921016383009394, 0.890789836169906], [0.021926768471832635, 0.9780732315281673], [0.2868822821763128, 0.7131177178236872], [0.37252507004145596, 0.627474929958544], [0.24832589482177678, 0.7516741051782232], [0.2753667085883821, 0.724633291411618], [0.6134214720714799, 0.3865785279285202], [0.5762800383893676, 0.42371996161063236], [0.22609678537571998, 0.7739032146242801], [0.3429659719860525, 0.6570340280139474], [0.39055920884017425, 0.6094407911598259], [0.30914212999974927, 0.6908578700002508], [0.440703412647522, 0.559296587352478], [0.30160527477620475, 0.6983947252237953], [0.30367420508405374, 0.6963257949159463], [0.15974122036383184, 0.8402587796361682], [0.264007776467404, 0.735992223532596], [0.2906247255685318, 0.7093752744314683], [0.4731129091456596, 0.5268870908543404], [0.2293242411789777, 0.7706757588210222], [0.5622294318967236, 0.4377705681032763], [0.4144264266368489, 0.585573573363151], [0.5969420869161383, 0.40305791308386185], [0.7055548953282628, 0.2944451046717373], [0.6878453458843995, 0.3121546541156005], [0.7703277520336851, 0.22967224796631483]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8166666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.1634 - val_loss: -0.7808\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8171 - val_loss: -0.8972\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8908 - val_loss: -0.9081\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8975 - val_loss: -0.9089\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8981 - val_loss: -0.9091\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8984 - val_loss: -0.9094\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.8987 - val_loss: -0.9097\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8990 - val_loss: -0.9099\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8993 - val_loss: -0.9102\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8997 - val_loss: -0.9106\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9003 - val_loss: -0.9110\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9010 - val_loss: -0.9114\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9121\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9029 - val_loss: -0.9131\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9145\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9163\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9096 - val_loss: -0.9183\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9126 - val_loss: -0.9202\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9150 - val_loss: -0.9213\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9168 - val_loss: -0.9226\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9179 - val_loss: -0.9228\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9186 - val_loss: -0.9240\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9196 - val_loss: -0.9222\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9196 - val_loss: -0.9228\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9188 - val_loss: -0.9231\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9155 - val_loss: -0.9248\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9192 - val_loss: -0.9249\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9202 - val_loss: -0.9251\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9209 - val_loss: -0.9246\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9208 - val_loss: -0.9245\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9211 - val_loss: -0.9249\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9217 - val_loss: -0.9250\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9213 - val_loss: -0.9240\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9213 - val_loss: -0.9244\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9217 - val_loss: -0.9250\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9222 - val_loss: -0.9247\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9219 - val_loss: -0.9247\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9218 - val_loss: -0.9251\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9224 - val_loss: -0.9254\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9223 - val_loss: -0.9251\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9221 - val_loss: -0.9251\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9223 - val_loss: -0.9247\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9214 - val_loss: -0.9247\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9222 - val_loss: -0.9252\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9226 - val_loss: -0.9251\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9225 - val_loss: -0.9252\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9225 - val_loss: -0.9249\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9223 - val_loss: -0.9250\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9224 - val_loss: -0.9253\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9224 - val_loss: -0.9252\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 810us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "[[0.16622267245578426, 0.8337773275442157], [0.16612426819187937, 0.8338757318081207], [0.4991190416938457, 0.5008809583061543], [0.3640185326994291, 0.6359814673005706], [0.14664377039726734, 0.8533562296027326], [0.48018809667380646, 0.5198119033261934], [0.5561200096149276, 0.4438799903850725], [0.018349814248103783, 0.9816501857518962], [0.3715522000372832, 0.6284477999627167], [0.6327387697635924, 0.3672612302364075], [0.5561549173040817, 0.4438450826959183], [0.3308905113485835, 0.6691094886514164], [0.5722294124903908, 0.42777058750960917], [0.6560441993882931, 0.3439558006117069], [0.7580929207037432, 0.24190707929625674], [0.09129293392909103, 0.9087070660709089], [0.36020015433739905, 0.6397998456626011], [0.2630247923542498, 0.7369752076457502], [0.11503255292325386, 0.8849674470767461], [0.27111690448689496, 0.7288830955131049], [0.0355534207281806, 0.9644465792718194], [0.018298480340789403, 0.9817015196592107], [0.019936248782709453, 0.9800637512172905], [0.018392865231246277, 0.9816071347687536], [0.020828859417950818, 0.9791711405820491], [0.21488551446093143, 0.7851144855390684], [0.35012663420986667, 0.6498733657901332], [0.6936564807812182, 0.3063435192187818], [0.7158152180060249, 0.2841847819939751], [0.6798849702598722, 0.32011502974012795], [0.3140404060350377, 0.6859595939649623], [0.379432637570596, 0.6205673624294041], [0.3275479961832769, 0.672452003816723], [0.4271393408469053, 0.5728606591530946], [0.48873539226104895, 0.511264607738951], [0.10272487932505295, 0.897275120674947], [0.011395692773395999, 0.988604307226604], [0.014938505375288088, 0.985061494624712], [0.32621812940157524, 0.6737818705984246], [0.014897756259658364, 0.9851022437403416], [0.67144526510309, 0.32855473489690995], [0.7290799708569962, 0.27092002914300384], [0.3636783514448222, 0.6363216485551778], [0.8929035622934554, 0.10709643770654467], [0.26753106405879534, 0.7324689359412045], [0.3107890253356493, 0.6892109746643507], [0.330174164119606, 0.669825835880394], [0.15966554332512617, 0.8403344566748738], [0.17739492884006888, 0.8226050711599311], [0.18307026003210147, 0.8169297399678983], [0.4718294028766254, 0.5281705971233747], [0.024094830267600176, 0.9759051697323998], [0.0500775799378273, 0.9499224200621728], [0.05354016530692368, 0.9464598346930764], [0.020232659154790316, 0.9797673408452096], [0.8328503416309341, 0.1671496583690659], [0.6225320133774239, 0.37746798662257586], [0.25436985489425007, 0.7456301451057499], [0.3651887454758484, 0.6348112545241515], [0.8393914102138469, 0.1606085897861531]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.85%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: -0.2142 - val_loss: -0.7731\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8258 - val_loss: -0.8818\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.8971 - val_loss: -0.8939\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9048 - val_loss: -0.8950\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9054 - val_loss: -0.8951\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9055 - val_loss: -0.8953\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9057 - val_loss: -0.8955\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9059 - val_loss: -0.8958\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9062 - val_loss: -0.8960\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9065 - val_loss: -0.8963\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9069 - val_loss: -0.8967\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9073 - val_loss: -0.8970\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9077 - val_loss: -0.8973\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9081 - val_loss: -0.8979\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9088 - val_loss: -0.8984\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9095 - val_loss: -0.8992\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9105 - val_loss: -0.9004\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9118 - val_loss: -0.9020\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9137 - val_loss: -0.9045\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9162 - val_loss: -0.9073\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9191 - val_loss: -0.9097\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9214 - val_loss: -0.9119\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9233 - val_loss: -0.9134\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9245 - val_loss: -0.9140\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9152\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9260 - val_loss: -0.9142\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9127\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9246 - val_loss: -0.9155\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9261 - val_loss: -0.9147\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9265 - val_loss: -0.9155\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9265 - val_loss: -0.9159\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9263 - val_loss: -0.9144\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9264 - val_loss: -0.9163\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9265 - val_loss: -0.9150\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9254 - val_loss: -0.9138\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9255 - val_loss: -0.9152\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9265 - val_loss: -0.9158\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9267 - val_loss: -0.9163\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9169\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9276 - val_loss: -0.9167\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9275 - val_loss: -0.9167\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9165\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9275 - val_loss: -0.9165\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9276 - val_loss: -0.9168\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9275 - val_loss: -0.9149\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9165\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9166\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9276 - val_loss: -0.9170\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9276 - val_loss: -0.9170\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9273 - val_loss: -0.9168\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 783us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "[[0.20737791094784525, 0.7926220890521548], [0.7545318945086168, 0.24546810549138323], [0.5817735865400092, 0.41822641345999073], [0.3066500418468882, 0.693349958153112], [0.3338516507802031, 0.6661483492197968], [0.04469448173481529, 0.9553055182651848], [0.08268168041041898, 0.917318319589581], [0.3822463807710903, 0.6177536192289097], [0.5702847268767712, 0.4297152731232289], [0.5556462063468235, 0.4443537936531765], [0.5735034506262148, 0.4264965493737852], [0.6245591830804621, 0.37544081691953796], [0.35544624126684543, 0.6445537587331545], [0.7899805702943572, 0.2100194297056429], [0.41611869000519375, 0.5838813099948061], [0.2933282945091376, 0.7066717054908624], [0.5138989790042945, 0.4861010209957055], [0.5699409802128239, 0.4300590197871762], [0.7319583853475773, 0.26804161465242277], [0.4703101169692862, 0.5296898830307137], [0.33254308006878097, 0.6674569199312188], [0.26576415430506617, 0.7342358456949337], [0.44316907603950634, 0.5568309239604936], [0.5492504211349043, 0.4507495788650957], [0.46993991113221695, 0.5300600888677831], [0.4638488944774741, 0.5361511055225259], [0.9233151949215421, 0.07668480507845789], [0.6656187454213199, 0.33438125457868006], [0.18607147521627376, 0.8139285247837262], [0.3706086877264921, 0.629391312273508], [0.22922597077820292, 0.770774029221797], [0.3088547278977724, 0.6911452721022275], [0.2594334192903903, 0.7405665807096098], [0.5071598537754853, 0.49284014622451466], [0.27128068752007845, 0.7287193124799214], [0.012685566772286832, 0.9873144332277132], [0.023990127731609162, 0.9760098722683908], [0.018368933486013483, 0.9816310665139865], [0.2799576122632932, 0.7200423877367068], [0.06377661202400614, 0.9362233879759938], [0.36338777785046045, 0.6366122221495396], [0.4689391048699766, 0.5310608951300234], [0.5306507465916119, 0.4693492534083882], [0.48155939707500545, 0.5184406029249946], [0.45626201655767495, 0.543737983442325], [0.42427668321738954, 0.5757233167826104], [0.26246124159999384, 0.7375387584000064], [0.3990112108493385, 0.6009887891506613], [0.17718782894848353, 0.8228121710515164], [0.2906652133371801, 0.7093347866628199], [0.046965810854601865, 0.9530341891453982], [0.010253944621289177, 0.989746055378711], [0.05918499645817822, 0.9408150035418219], [0.29014098253795795, 0.709859017462042], [0.010487566541002257, 0.9895124334589978], [0.544002646153407, 0.4559973538465931], [0.4701368132491013, 0.5298631867508987], [0.803649024919246, 0.1963509750807541], [0.5906353070344247, 0.4093646929655753], [0.7071654168655409, 0.29283458313445904]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.6833333333333333%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2434 - val_loss: -0.7814\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.8262 - val_loss: -0.8893\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8964 - val_loss: -0.8994\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9024 - val_loss: -0.9001\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9029 - val_loss: -0.9004\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9032 - val_loss: -0.9007\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9034 - val_loss: -0.9009\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9036 - val_loss: -0.9011\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.9013\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9015\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9044 - val_loss: -0.9018\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9047 - val_loss: -0.9021\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9052 - val_loss: -0.9024\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9057 - val_loss: -0.9028\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9034\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9071 - val_loss: -0.9043\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9083 - val_loss: -0.9056\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9099 - val_loss: -0.9072\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9120 - val_loss: -0.9099\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9151 - val_loss: -0.9125\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9181 - val_loss: -0.9148\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9201 - val_loss: -0.9163\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9218 - val_loss: -0.9174\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9229 - val_loss: -0.9181\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9237 - val_loss: -0.9192\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9243 - val_loss: -0.9183\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9177\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9228 - val_loss: -0.9144\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9158 - val_loss: -0.9095\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9205 - val_loss: -0.9163\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9222 - val_loss: -0.9142\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9218 - val_loss: -0.9177\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9233 - val_loss: -0.9197\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9190\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9200\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9198\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9190\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9246 - val_loss: -0.9202\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9249 - val_loss: -0.9202\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9203\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9199\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9189\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9244 - val_loss: -0.9202\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9253 - val_loss: -0.9196\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9247 - val_loss: -0.9192\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9243 - val_loss: -0.9197\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9239 - val_loss: -0.9182\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9225 - val_loss: -0.9190\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9244 - val_loss: -0.9183\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9192\n",
      "3/3 [==============================] - 0s 986us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 814us/step\n",
      "19/19 [==============================] - 0s 811us/step\n",
      "[[0.08160848282455292, 0.9183915171754471], [0.12858823478030013, 0.8714117652196999], [0.12917978629047785, 0.8708202137095222], [0.16677753778114096, 0.8332224622188591], [0.10608981530933172, 0.8939101846906683], [0.012390847380353818, 0.9876091526196463], [0.014365187963805162, 0.9856348120361949], [0.009083439234752907, 0.9909165607652471], [0.009654444095475754, 0.9903455559045242], [0.6082501498837921, 0.3917498501162079], [0.4821598452917333, 0.5178401547082667], [0.5132585944256576, 0.48674140557434237], [0.1951524365085709, 0.8048475634914292], [0.22565138926206307, 0.774348610737937], [0.6130819909076983, 0.38691800909230145], [0.09438052825129908, 0.9056194717487009], [0.1621887801941283, 0.8378112198058718], [0.15426034726324556, 0.8457396527367547], [0.22581715003154607, 0.774182849968454], [0.2651117830108954, 0.7348882169891047], [0.2043217657368322, 0.7956782342631676], [0.08904112372418367, 0.9109588762758163], [0.4844403077432009, 0.5155596922567991], [0.2690227719954552, 0.7309772280045448], [0.27473258677494755, 0.7252674132250524], [0.463383257116612, 0.5366167428833881], [0.7097874139856386, 0.29021258601436134], [0.5845936764994198, 0.41540632350058004], [0.5649654638746243, 0.4350345361253758], [0.4820399461270557, 0.5179600538729443], [0.4449779630634172, 0.5550220369365828], [0.1543588836829775, 0.8456411163170225], [0.10641207536200747, 0.8935879246379925], [0.49063972416104107, 0.5093602758389588], [0.09107731900430244, 0.9089226809956976], [0.016779525325004728, 0.9832204746749953], [0.008438594135743088, 0.991561405864257], [0.02076234596465603, 0.979237654035344], [0.08185954122870394, 0.918140458771296], [0.053222665703445346, 0.9467773342965546], [0.3559909417989783, 0.6440090582010216], [0.6828125357856593, 0.31718746421434074], [0.7011631123640003, 0.29883688763599964], [0.6635827987538261, 0.336417201246174], [0.7104143883080574, 0.28958561169194263], [0.41297862800380347, 0.5870213719961965], [0.4962406501951251, 0.5037593498048749], [0.6719989529031105, 0.32800104709688943], [0.34380782321370323, 0.6561921767862968], [0.13702169034155284, 0.8629783096584471], [0.43972171647626657, 0.5602782835237333], [0.5348479237009374, 0.4651520762990625], [0.3977037930000213, 0.6022962069999787], [0.5452011976853735, 0.45479880231462655], [0.5485533374782483, 0.4514466625217517], [0.6087491875531303, 0.39125081244686966], [0.2091024342401232, 0.7908975657598769], [0.4050265661925336, 0.5949734338074665], [0.660327164773407, 0.33967283522659314], [0.6675212928930773, 0.33247870710692273], [0.2204509938988563, 0.7795490061011439], [0.2627837373612647, 0.7372162626387353], [0.5371227237695491, 0.46287727623045094], [0.4725233143490259, 0.5274766856509743], [0.5313754246129893, 0.46862457538701086], [0.3329613318862069, 0.6670386681137932], [0.3444874032342358, 0.655512596765764], [0.24353417083263562, 0.7564658291673645], [0.16098553829697998, 0.8390144617030201], [0.44303518778707596, 0.5569648122129242], [0.46996793899057593, 0.5300320610094241], [0.38323656848063303, 0.6167634315193671], [0.28988461969761414, 0.7101153803023857], [0.6307070886625102, 0.36929291133748987], [0.18740647089288603, 0.812593529107114]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7466666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: -0.2206 - val_loss: -0.7826\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.8261 - val_loss: -0.8898\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8968 - val_loss: -0.9002\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9030 - val_loss: -0.9006\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9031 - val_loss: -0.9007\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9032 - val_loss: -0.9009\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9033 - val_loss: -0.9010\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9035 - val_loss: -0.9012\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9036 - val_loss: -0.9014\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9038 - val_loss: -0.9015\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9040 - val_loss: -0.9017\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9042 - val_loss: -0.9020\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9023\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9049 - val_loss: -0.9027\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9053 - val_loss: -0.9031\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9058 - val_loss: -0.9036\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9043\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9072 - val_loss: -0.9052\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9084 - val_loss: -0.9065\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9100 - val_loss: -0.9083\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9122 - val_loss: -0.9104\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9146 - val_loss: -0.9124\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9167 - val_loss: -0.9141\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9188 - val_loss: -0.9158\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9205 - val_loss: -0.9166\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9214 - val_loss: -0.9175\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9224 - val_loss: -0.9179\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9182\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9182\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9239 - val_loss: -0.9189\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9242 - val_loss: -0.9191\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9242 - val_loss: -0.9193\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9238 - val_loss: -0.9167\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9232 - val_loss: -0.9174\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9235 - val_loss: -0.9193\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9153\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9203 - val_loss: -0.9175\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9227 - val_loss: -0.9185\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9237 - val_loss: -0.9190\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9186\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9243 - val_loss: -0.9188\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9243 - val_loss: -0.9187\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9245 - val_loss: -0.9188\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9242 - val_loss: -0.9136\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9180 - val_loss: -0.8965\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9071 - val_loss: -0.8997\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9017 - val_loss: -0.8991\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9014 - val_loss: -0.8991\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9014 - val_loss: -0.8991\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9014 - val_loss: -0.8992\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 932us/step\n",
      "[[0.3080093841826044, 0.6919906158173956], [0.545244142848093, 0.45475585715190714], [0.5500321936083896, 0.44996780639161027], [0.2904226377848917, 0.7095773622151083], [0.24900572853360778, 0.7509942714663922], [0.18613198980643347, 0.8138680101935665], [0.25545617612644184, 0.744543823873558], [0.5395028543370062, 0.4604971456629937], [0.4166831896499521, 0.5833168103500479], [0.3660657184920073, 0.6339342815079926], [0.32666623832125163, 0.6733337616787484], [0.6131773065782236, 0.3868226934217764], [0.45696042533457887, 0.5430395746654212], [0.7762606561071452, 0.22373934389285483], [0.36757991314865895, 0.6324200868513412], [0.3140617279934623, 0.6859382720065376], [0.20914558604203093, 0.7908544139579692], [0.1276872878707547, 0.8723127121292452], [0.2429706559878026, 0.7570293440121973], [0.29224872093401494, 0.7077512790659851], [0.13392542238462488, 0.8660745776153751], [0.1300883710660486, 0.8699116289339515], [0.08311148153882858, 0.9168885184611715], [0.07239282842066647, 0.9276071715793335], [0.10784160282540638, 0.8921583971745937], [0.23054571183367623, 0.7694542881663239], [0.4459638955669498, 0.5540361044330502], [0.4731700010626073, 0.5268299989373927], [0.4285460221730021, 0.5714539778269978], [0.21962609454249862, 0.7803739054575014], [0.4392333442812145, 0.5607666557187855], [0.7270310643024438, 0.27296893569755615], [0.13975790110451614, 0.8602420988954839], [0.31548013029678434, 0.6845198697032157], [0.5577595465416589, 0.4422404534583411], [0.20038310585738955, 0.7996168941426104], [0.3175342191163504, 0.6824657808836498], [0.2827971537401873, 0.7172028462598126], [0.17547098415634166, 0.8245290158436583], [0.36161910295883903, 0.638380897041161], [0.5113578742092022, 0.4886421257907978], [0.5364077662629803, 0.46359223373701974], [0.4821474089505562, 0.5178525910494438], [0.5759969962004772, 0.4240030037995229], [0.4776833104771626, 0.5223166895228373], [0.24367996144938628, 0.7563200385506137], [0.23908325695463284, 0.760916743045367], [0.21465369258971267, 0.7853463074102873], [0.38533728779426124, 0.6146627122057388], [0.36606773112103286, 0.6339322688789671], [0.15113730388888308, 0.848862696111117], [0.18750101520459173, 0.8124989847954084], [0.2583232830853781, 0.7416767169146219], [0.16097223841430885, 0.8390277615856911], [0.18148377561599704, 0.818516224384003], [0.3249528383787097, 0.6750471616212903], [0.237951416033174, 0.7620485839668261], [0.21748583843899308, 0.782514161561007], [0.35848692583050634, 0.6415130741694937], [0.5281110388569784, 0.4718889611430217], [0.20603198204520456, 0.7939680179547953], [0.47000513219189793, 0.5299948678081021], [0.4839072306339029, 0.5160927693660972], [0.3822809306418635, 0.6177190693581365], [0.36094572670102154, 0.6390542732989783], [0.07806340374748705, 0.9219365962525129], [0.15609683873081226, 0.8439031612691877], [0.1570329410770133, 0.8429670589229867], [0.21028040799257222, 0.7897195920074278], [0.14732452289258544, 0.8526754771074144], [0.610184842147883, 0.38981515785211696], [0.33714905007477447, 0.6628509499252254], [0.41171970691762333, 0.5882802930823767], [0.37405607104364047, 0.6259439289563595], [0.664954455618714, 0.33504554438128586]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7066666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2442 - val_loss: -0.7903\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8296 - val_loss: -0.8912\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8963 - val_loss: -0.9013\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9028 - val_loss: -0.9019\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9033 - val_loss: -0.9020\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9034 - val_loss: -0.9022\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9036 - val_loss: -0.9024\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9038 - val_loss: -0.9025\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9040 - val_loss: -0.9027\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9042 - val_loss: -0.9029\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9045 - val_loss: -0.9030\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9047 - val_loss: -0.9032\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9050 - val_loss: -0.9034\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9052 - val_loss: -0.9035\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9054 - val_loss: -0.9036\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9056 - val_loss: -0.9038\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9059 - val_loss: -0.9041\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9043\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9045\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9066 - val_loss: -0.9046\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9069 - val_loss: -0.9048\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9072 - val_loss: -0.9050\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9075 - val_loss: -0.9054\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.9058\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9085 - val_loss: -0.9065\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9093 - val_loss: -0.9074\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9105 - val_loss: -0.9085\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9120 - val_loss: -0.9102\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9143 - val_loss: -0.9127\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9180 - val_loss: -0.9130\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9205 - val_loss: -0.9183\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9235 - val_loss: -0.9179\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9193\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9251 - val_loss: -0.9162\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9228 - val_loss: -0.9196\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9157\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9194\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9189\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9259 - val_loss: -0.9207\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9274 - val_loss: -0.9220\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9281 - val_loss: -0.9197\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9059\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9129 - val_loss: -0.9010\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9036 - val_loss: -0.9006\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9033 - val_loss: -0.9033\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9076 - val_loss: -0.9125\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9160 - val_loss: -0.9090\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9189 - val_loss: -0.9163\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9229 - val_loss: -0.9175\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9238 - val_loss: -0.9203\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 764us/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "[[0.583306002300634, 0.41669399769936605], [0.4282213035757528, 0.5717786964242473], [0.7553658501435199, 0.24463414985648005], [0.34038425667361916, 0.6596157433263807], [0.5576219711805172, 0.4423780288194828], [0.3222484383544817, 0.6777515616455183], [0.5996300373517092, 0.40036996264829094], [0.6276780182470295, 0.3723219817529705], [0.5310581994390289, 0.4689418005609713], [0.5136934878726892, 0.48630651212731085], [0.44165317114346264, 0.5583468288565374], [0.6391066078387451, 0.36089339216125504], [0.7378116073761926, 0.2621883926238075], [0.13995795559703533, 0.8600420444029648], [0.43518401740356294, 0.5648159825964371], [0.2183583561246974, 0.7816416438753027], [0.45949575918966784, 0.5405042408103321], [0.38717923876043026, 0.6128207612395697], [0.7117226882643355, 0.28827731173566445], [0.3524058892131895, 0.6475941107868106], [0.24501416000195458, 0.7549858399980455], [0.34962026259433254, 0.6503797374056673], [0.22907153587122822, 0.7709284641287717], [0.36094531696964716, 0.639054683030353], [0.34792698998868266, 0.6520730100113173], [0.47800291828739316, 0.5219970817126068], [0.5519802958971594, 0.4480197041028407], [0.3748830087780871, 0.6251169912219129], [0.5854792521090046, 0.41452074789099524], [0.32594275393315736, 0.6740572460668424], [0.663539009891019, 0.33646099010898095], [0.2747449783082986, 0.7252550216917015], [0.15746164609890995, 0.8425383539010901], [0.41257004965423616, 0.587429950345764], [0.11438342803867659, 0.8856165719613236], [0.20725991211057032, 0.7927400878894297], [0.16641380491018448, 0.8335861950898154], [0.2565047209309917, 0.7434952790690083], [0.16040553011951716, 0.8395944698804828], [0.18872034381560537, 0.8112796561843948], [0.5201246132105659, 0.4798753867894342], [0.15293174431351894, 0.8470682556864811], [0.5155495012020787, 0.48445049879792146], [0.629908627916107, 0.370091372083893], [0.477919686089293, 0.5220803139107071], [0.22018843971359683, 0.7798115602864031], [0.42713854052433775, 0.5728614594756622], [0.6826565331884757, 0.31734346681152414], [0.6697689648434025, 0.3302310351565976], [0.5712868800401347, 0.4287131199598652], [0.05312240341003889, 0.9468775965899612], [0.009456174739893389, 0.9905438252601066], [0.00916818891065552, 0.9908318110893444], [0.25506329113924053, 0.7449367088607595], [0.003994715525269417, 0.9960052844747307], [0.5736420024033588, 0.4263579975966411], [0.6578114966077389, 0.3421885033922611], [0.7330532006037691, 0.26694679939623095], [0.640579867312349, 0.359420132687651], [0.3741855323964153, 0.6258144676035848], [0.15142856392450338, 0.8485714360754966], [0.2201471106355043, 0.7798528893644957], [0.22598682136286743, 0.7740131786371325], [0.17188344739884562, 0.8281165526011545], [0.19141045995315356, 0.8085895400468466], [0.36443114911845303, 0.6355688508815469], [0.3009134210481217, 0.6990865789518783], [0.4294557420788258, 0.5705442579211741], [0.3418846213066642, 0.6581153786933358], [0.28242835421023793, 0.7175716457897621], [0.2903506895121528, 0.7096493104878472], [0.5629173244467705, 0.4370826755532296], [0.6002625071250357, 0.3997374928749643], [0.7221420673225456, 0.27785793267745446], [0.6837855062355198, 0.3162144937644803]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7066666666666667%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: -0.2936 - val_loss: -0.8072\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8445 - val_loss: -0.8935\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8994 - val_loss: -0.8997\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9031 - val_loss: -0.9002\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9035 - val_loss: -0.9004\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9038 - val_loss: -0.9006\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9039 - val_loss: -0.9007\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9041 - val_loss: -0.9009\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9042 - val_loss: -0.9010\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9043 - val_loss: -0.9012\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9045 - val_loss: -0.9013\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9046 - val_loss: -0.9015\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9048 - val_loss: -0.9017\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9050 - val_loss: -0.9019\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9051 - val_loss: -0.9020\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9053 - val_loss: -0.9023\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9055 - val_loss: -0.9025\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9057 - val_loss: -0.9028\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: -0.9059 - val_loss: -0.9031\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9061 - val_loss: -0.9034\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9038\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9068 - val_loss: -0.9043\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9074 - val_loss: -0.9050\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9081 - val_loss: -0.9061\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9093 - val_loss: -0.9075\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9112 - val_loss: -0.9100\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9139 - val_loss: -0.9131\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9171 - val_loss: -0.9151\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9197 - val_loss: -0.9156\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9200 - val_loss: -0.9178\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9209 - val_loss: -0.9144\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: -0.9210 - val_loss: -0.9189\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9219 - val_loss: -0.9180\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9220 - val_loss: -0.9135\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9210 - val_loss: -0.9161\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9214 - val_loss: -0.9174\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9223 - val_loss: -0.9199\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9189\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9201\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9251 - val_loss: -0.9199\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9252 - val_loss: -0.9202\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9250 - val_loss: -0.9201\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9193\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: -0.9250 - val_loss: -0.9202\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9251 - val_loss: -0.9211\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9208\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9256 - val_loss: -0.9207\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9258 - val_loss: -0.9207\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9201\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9255 - val_loss: -0.9202\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 761us/step\n",
      "19/19 [==============================] - 0s 871us/step\n",
      "[[0.29626491875430494, 0.7037350812456951], [0.5799495759690525, 0.4200504240309475], [0.32974005469310874, 0.6702599453068911], [0.25653962635732486, 0.743460373642675], [0.26417176260368747, 0.7358282373963126], [0.1612463167868925, 0.8387536832131076], [0.226844553929137, 0.773155446070863], [0.2502163139597645, 0.7497836860402356], [0.2667888842521108, 0.7332111157478891], [0.19534963297360877, 0.8046503670263914], [0.4027603798532947, 0.5972396201467053], [0.4412318192491924, 0.5587681807508076], [0.455039050412846, 0.5449609495871541], [0.442473654024208, 0.5575263459757919], [0.5939965879270426, 0.4060034120729573], [0.4392437977545222, 0.5607562022454777], [0.2511068230717562, 0.7488931769282438], [0.3807684089933475, 0.6192315910066525], [0.15216259272003332, 0.8478374072799666], [0.17930341443711728, 0.8206965855628828], [0.35240979196050165, 0.6475902080394984], [0.6277289297890786, 0.37227107021092143], [0.07747690816130236, 0.9225230918386975], [0.02221148743120386, 0.9777885125687962], [0.04672638270047409, 0.9532736172995259], [0.24653565584835763, 0.7534643441516424], [0.48558503484446686, 0.5144149651555332], [0.46764514534627055, 0.5323548546537294], [0.4808127321321122, 0.5191872678678877], [0.45604502583304474, 0.5439549741669553], [0.37741528419351084, 0.6225847158064892], [0.3237620692099074, 0.6762379307900928], [0.2516014970300981, 0.748398502969902], [0.25554101490533315, 0.7444589850946668], [0.3093597673496856, 0.6906402326503145], [0.03401865491417241, 0.9659813450858277], [0.036531327139161095, 0.9634686728608388], [0.027874024276906325, 0.9721259757230936], [0.0301937734698406, 0.9698062265301594], [0.024372927121136225, 0.9756270728788639], [0.5031130598844606, 0.49688694011553936], [0.78576272838233, 0.21423727161766998], [0.5978387845485761, 0.4021612154514238], [0.408416139807304, 0.5915838601926958], [0.6089427131266063, 0.3910572868733936], [0.3217355594812855, 0.6782644405187146], [0.2674653272636403, 0.7325346727363595], [0.5710190025009602, 0.4289809974990399], [0.33682037304338686, 0.6631796269566133], [0.3463286103555471, 0.6536713896444529], [0.4042867237584552, 0.5957132762415449], [0.11863320665886476, 0.8813667933411352], [0.07025959955640522, 0.9297404004435947], [0.2765509895994002, 0.7234490104005998], [0.5865154853065888, 0.4134845146934112], [0.5055515725497259, 0.49444842745027406], [0.39087785433345, 0.6091221456665499], [0.6268677779989016, 0.37313222200109836], [0.5200758834256338, 0.4799241165743661], [0.7618753653350361, 0.23812463466496392], [0.30048542008069257, 0.6995145799193075], [0.2837202615468144, 0.7162797384531858], [0.30636493987655233, 0.6936350601234478], [0.22107374470794766, 0.7789262552920524], [0.136080276673416, 0.8639197233265841], [0.15165628025365385, 0.8483437197463461], [0.024250090824826164, 0.9757499091751739], [0.029508960739351567, 0.9704910392606485], [0.39615510831608214, 0.6038448916839179], [0.341752388487425, 0.658247611512575], [0.5211516765592759, 0.4788483234407242], [0.467381272835202, 0.5326187271647982], [0.5705864499595433, 0.42941355004045667], [0.3205840180605205, 0.6794159819394794], [0.6038927695311305, 0.3961072304688695]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7733333333333333%\n",
      "-----------------------------------------\n",
      "(600, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: -0.2420 - val_loss: -0.7770\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8170 - val_loss: -0.8903\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8923 - val_loss: -0.9030\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9003 - val_loss: -0.9040\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9009 - val_loss: -0.9042\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9011 - val_loss: -0.9044\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9013 - val_loss: -0.9045\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: -0.9015 - val_loss: -0.9047\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9016 - val_loss: -0.9048\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9018 - val_loss: -0.9050\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9019 - val_loss: -0.9052\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9020 - val_loss: -0.9054\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9022 - val_loss: -0.9056\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9024 - val_loss: -0.9058\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9025 - val_loss: -0.9061\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9027 - val_loss: -0.9063\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9029 - val_loss: -0.9066\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9031 - val_loss: -0.9069\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9034 - val_loss: -0.9072\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9037 - val_loss: -0.9077\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9041 - val_loss: -0.9082\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9046 - val_loss: -0.9089\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9053 - val_loss: -0.9098\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9111\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9075 - val_loss: -0.9127\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9095 - val_loss: -0.9151\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9124 - val_loss: -0.9178\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9155 - val_loss: -0.9202\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9184 - val_loss: -0.9211\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9197 - val_loss: -0.9184\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9199 - val_loss: -0.9233\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9215 - val_loss: -0.9225\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9218 - val_loss: -0.9241\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9229 - val_loss: -0.9237\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9233 - val_loss: -0.9217\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9222 - val_loss: -0.9232\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9219 - val_loss: -0.9229\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9231 - val_loss: -0.9240\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9223 - val_loss: -0.9178\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9195 - val_loss: -0.9222\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9175 - val_loss: -0.9236\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9212 - val_loss: -0.9228\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9231\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9196 - val_loss: -0.9145\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9172 - val_loss: -0.9127\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9091 - val_loss: -0.9188\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9193 - val_loss: -0.9206\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9199 - val_loss: -0.9127\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9165 - val_loss: -0.9182\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9196 - val_loss: -0.9189\n",
      "3/3 [==============================] - 0s 990us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 734us/step\n",
      "19/19 [==============================] - 0s 870us/step\n",
      "[[0.45224944695570135, 0.5477505530442988], [0.43507557271755726, 0.5649244272824427], [0.39343185743459697, 0.6065681425654029], [0.13997793576334214, 0.8600220642366578], [0.6473311439286875, 0.3526688560713126], [0.5209747638107564, 0.47902523618924364], [0.5379552987966916, 0.4620447012033083], [0.4803244879821501, 0.5196755120178499], [0.5127899133085149, 0.4872100866914852], [0.5215794793864341, 0.4784205206135659], [0.42248363967421987, 0.57751636032578], [0.5499286394023236, 0.4500713605976764], [0.45339999910172485, 0.5466000008982752], [0.6444300281082337, 0.35556997189176637], [0.5508406783087161, 0.449159321691284], [0.5237176294690746, 0.47628237053092526], [0.43499730294343936, 0.5650026970565607], [0.37306612442068365, 0.6269338755793165], [0.30266210853774644, 0.6973378914622537], [0.4741847449127229, 0.5258152550872772], [0.05411201816480969, 0.9458879818351903], [0.29674058967890243, 0.7032594103210975], [0.08030637053542526, 0.9196936294645748], [0.011487141709312695, 0.9885128582906872], [0.0065201389514813754, 0.9934798610485186], [0.6712906610298075, 0.3287093389701925], [0.2689988095379905, 0.7310011904620095], [0.5546030160057722, 0.4453969839942278], [0.7080254413664715, 0.29197455863352845], [0.4518581484182921, 0.548141851581708], [0.5629955412795488, 0.4370044587204511], [0.4821915533403337, 0.5178084466596663], [0.5047157192830709, 0.4952842807169291], [0.12309591856518268, 0.8769040814348172], [0.20265529244644703, 0.7973447075535529], [0.03368314797916627, 0.9663168520208336], [0.007567940666493856, 0.9924320593335062], [0.03254413322293628, 0.9674558667770636], [0.27473214361994286, 0.7252678563800572], [0.02241446289253637, 0.9775855371074635], [0.5242893470803041, 0.47571065291969583], [0.42368053611146533, 0.5763194638885347], [0.5933393943291178, 0.40666060567088214], [0.5582159803677114, 0.44178401963228864], [0.4079950684205802, 0.5920049315794199], [0.39512306406303566, 0.6048769359369643], [0.4319221192500127, 0.5680778807499873], [0.15080240693444594, 0.849197593065554], [0.29794965033603493, 0.7020503496639651], [0.30683085263340726, 0.6931691473665929], [0.2514623524933236, 0.7485376475066765], [0.07007714794937539, 0.9299228520506246], [0.20675507791863865, 0.7932449220813613], [0.10263038203827031, 0.8973696179617298], [0.08883005882755646, 0.9111699411724435], [0.7545509036934851, 0.24544909630651496], [0.6686959504441516, 0.33130404955584836], [0.5535054643122435, 0.44649453568775654], [0.6159395442164128, 0.3840604557835872], [0.46869451460909617, 0.5313054853909038], [0.17142194694428153, 0.8285780530557184], [0.1816095301499119, 0.8183904698500881], [0.13120010815880429, 0.8687998918411957], [0.1584157691797489, 0.8415842308202511], [0.13073704539573658, 0.8692629546042634], [0.5087902185187361, 0.49120978148126404], [0.40407256509292616, 0.5959274349070739], [0.03862397995039827, 0.9613760200496018], [0.39728651491013933, 0.6027134850898607], [0.6649353723198872, 0.3350646276801128], [0.6459697466266963, 0.3540302533733037], [0.7673060986070781, 0.23269390139292184], [0.4283405404854216, 0.5716594595145784], [0.46602445752477395, 0.533975542475226], [0.5742664406878039, 0.42573355931219614]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7466666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2103 - val_loss: -0.7710\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8180 - val_loss: -0.8882\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8940 - val_loss: -0.9007\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9018 - val_loss: -0.9016\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9023 - val_loss: -0.9017\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9024 - val_loss: -0.9019\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: -0.9026 - val_loss: -0.9022\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9029 - val_loss: -0.9025\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9034 - val_loss: -0.9029\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9039 - val_loss: -0.9034\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9046 - val_loss: -0.9039\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9054 - val_loss: -0.9046\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9065 - val_loss: -0.9058\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9080 - val_loss: -0.9073\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9103 - val_loss: -0.9093\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9131 - val_loss: -0.9114\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9161 - val_loss: -0.9135\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9188 - val_loss: -0.9151\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9208 - val_loss: -0.9164\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9222 - val_loss: -0.9177\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9234 - val_loss: -0.9183\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9246 - val_loss: -0.9187\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9246 - val_loss: -0.9193\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9257 - val_loss: -0.9195\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9258 - val_loss: -0.9195\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9259 - val_loss: -0.9195\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9261 - val_loss: -0.9175\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9250 - val_loss: -0.9194\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9258 - val_loss: -0.9177\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9249 - val_loss: -0.9196\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9256 - val_loss: -0.9184\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9254 - val_loss: -0.9200\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9163\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9245 - val_loss: -0.9194\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9247 - val_loss: -0.9182\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9168\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9252 - val_loss: -0.9186\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9260 - val_loss: -0.9183\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9254 - val_loss: -0.9198\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9252 - val_loss: -0.9195\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9196\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9261 - val_loss: -0.9195\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9188\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9262 - val_loss: -0.9190\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9194\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9263 - val_loss: -0.9203\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9267 - val_loss: -0.9199\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9269 - val_loss: -0.9198\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9268 - val_loss: -0.9199\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9192\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 784us/step\n",
      "20/20 [==============================] - 0s 859us/step\n",
      "[[0.29683256746757003, 0.70316743253243], [0.2823490445246082, 0.7176509554753917], [0.26430280113497545, 0.7356971988650245], [0.35106772533802055, 0.6489322746619796], [0.3994757573600475, 0.6005242426399524], [0.23011392456531946, 0.7698860754346806], [0.03332649580414831, 0.9666735041958516], [0.031390881522921334, 0.9686091184770788], [0.02625340165177636, 0.9737465983482236], [0.024976262813155712, 0.9750237371868442], [0.4059611545533696, 0.5940388454466303], [0.4590882739438466, 0.5409117260561533], [0.5864474586347633, 0.41355254136523667], [0.32143722277981535, 0.6785627772201845], [0.21534542560592465, 0.7846545743940753], [0.4741120245172885, 0.5258879754827116], [0.1902347622390712, 0.8097652377609288], [0.21764222948123152, 0.7823577705187685], [0.27648651769925126, 0.7235134823007487], [0.5014492036442532, 0.49855079635574684], [0.5143792812313284, 0.48562071876867163], [0.47389714649263937, 0.5261028535073605], [0.24879984547578105, 0.7512001545242188], [0.3415789624245724, 0.6584210375754276], [0.43081919996193513, 0.5691808000380649], [0.3571791623647096, 0.6428208376352904], [0.4937846871632029, 0.5062153128367971], [0.6024266657537494, 0.3975733342462507], [0.39490804940666857, 0.6050919505933314], [0.3588478119621743, 0.6411521880378257], [0.30683710474000947, 0.6931628952599905], [0.6435393490245112, 0.35646065097548885], [0.3071437931730352, 0.6928562068269648], [0.49340340614660627, 0.5065965938533938], [0.19714088719476244, 0.8028591128052376], [0.2358920793497834, 0.7641079206502166], [0.1730339667073822, 0.8269660332926179], [0.15814648944420978, 0.8418535105557902], [0.2584059406427523, 0.7415940593572476], [0.1477434838168877, 0.8522565161831123], [0.3267902900338985, 0.6732097099661015], [0.5039092154121915, 0.49609078458780853], [0.2564906248244415, 0.7435093751755585], [0.5432777541580879, 0.4567222458419121], [0.2986312342323068, 0.7013687657676932], [0.3474287110366887, 0.6525712889633113], [0.2573206077452985, 0.7426793922547015], [0.201234465768392, 0.798765534231608], [0.35409953006109174, 0.6459004699389082], [0.4675615181809645, 0.5324384818190355], [0.3872302697315769, 0.612769730268423], [0.4281436098907224, 0.5718563901092777], [0.4226070266718489, 0.5773929733281511], [0.23039691006585444, 0.7696030899341455], [0.4314762673349022, 0.5685237326650978], [0.5420835579915159, 0.45791644200848414], [0.4408346596161086, 0.5591653403838913], [0.4323934758257606, 0.5676065241742394], [0.6573770205462869, 0.3426229794537131], [0.3317890535163226, 0.6682109464836775]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7166666666666667%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: -0.2189 - val_loss: -0.7783\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8262 - val_loss: -0.8871\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8976 - val_loss: -0.8986\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9053 - val_loss: -0.8996\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9060 - val_loss: -0.8998\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9062 - val_loss: -0.9002\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9064 - val_loss: -0.9003\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9065 - val_loss: -0.9005\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9067 - val_loss: -0.9007\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9069 - val_loss: -0.9009\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9072 - val_loss: -0.9010\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: -0.9074 - val_loss: -0.9013\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9077 - val_loss: -0.9014\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9079 - val_loss: -0.9017\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9082 - val_loss: -0.9020\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9086 - val_loss: -0.9024\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9091 - val_loss: -0.9028\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9097 - val_loss: -0.9035\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9106 - val_loss: -0.9044\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9118 - val_loss: -0.9056\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9135 - val_loss: -0.9074\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9157 - val_loss: -0.9094\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9183 - val_loss: -0.9116\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9207 - val_loss: -0.9133\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9227 - val_loss: -0.9145\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9242 - val_loss: -0.9157\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9165\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9255 - val_loss: -0.9156\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9261 - val_loss: -0.9170\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9268 - val_loss: -0.9172\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9269 - val_loss: -0.9178\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9274 - val_loss: -0.9180\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9277 - val_loss: -0.9181\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9279 - val_loss: -0.9182\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9281 - val_loss: -0.9183\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9279 - val_loss: -0.9139\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9244 - val_loss: -0.9162\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9154\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: -0.9247 - val_loss: -0.9149\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9251 - val_loss: -0.9126\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9163\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9258 - val_loss: -0.9174\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9154\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9267 - val_loss: -0.9159\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9140\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9267 - val_loss: -0.9161\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9257 - val_loss: -0.9162\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9265 - val_loss: -0.9183\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9276 - val_loss: -0.9180\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 764us/step\n",
      "20/20 [==============================] - 0s 904us/step\n",
      "[[0.19178530093684995, 0.80821469906315], [0.20687743375032974, 0.7931225662496703], [0.2917129063720012, 0.7082870936279988], [0.1725030094495543, 0.8274969905504458], [0.20211702393921227, 0.7978829760607875], [0.23203960908845445, 0.7679603909115454], [0.0058171448277318525, 0.9941828551722682], [0.12851907131169724, 0.8714809286883027], [0.024112889950630517, 0.9758871100493696], [0.2580577358944193, 0.7419422641055806], [0.21458025919934956, 0.7854197408006505], [0.30261271339898554, 0.6973872866010145], [0.22230315598433775, 0.7776968440156623], [0.645130895671159, 0.354869104328841], [0.588343278297636, 0.411656721702364], [0.18260772173476514, 0.8173922782652348], [0.1958535944078408, 0.8041464055921592], [0.2594399702240443, 0.7405600297759556], [0.25317301076233867, 0.7468269892376613], [0.09336585090160486, 0.9066341490983952], [0.18474248641415186, 0.8152575135858481], [0.23023804121908187, 0.7697619587809181], [0.3231013705741364, 0.6768986294258637], [0.3988967798354843, 0.6011032201645156], [0.27504879413446526, 0.7249512058655347], [0.5354257725540118, 0.4645742274459882], [0.6118159259568574, 0.3881840740431426], [0.2208689101383625, 0.7791310898616375], [0.4687711790316662, 0.5312288209683338], [0.5073699282328515, 0.49263007176714846], [0.16507690503316969, 0.8349230949668305], [0.3452049214437096, 0.6547950785562906], [0.29527348988763724, 0.7047265101123626], [0.15176249295296212, 0.8482375070470378], [0.27726810038781047, 0.7227318996121894], [0.04920845858704341, 0.9507915414129566], [0.0108057726796654, 0.9891942273203345], [0.009212730231074974, 0.990787269768925], [0.011753781798207545, 0.9882462182017924], [0.015344346145046133, 0.9846556538549538], [0.3311144014193398, 0.66888559858066], [0.30767139266111854, 0.6923286073388817], [0.44656553011404737, 0.5534344698859527], [0.49201765935148095, 0.5079823406485191], [0.5727267172756858, 0.42727328272431425], [0.18908306695313326, 0.8109169330468666], [0.36111055165379746, 0.6388894483462024], [0.38334122908509405, 0.6166587709149062], [0.539779865844474, 0.460220134155526], [0.36033000597186404, 0.6396699940281358], [0.053425995396943864, 0.9465740046030561], [0.0213571642584824, 0.9786428357415177], [0.1710314655142563, 0.8289685344857436], [0.08598030193379123, 0.9140196980662088], [0.10071382683357241, 0.8992861731664274], [0.5145542577572144, 0.48544574224278564], [0.1825737306037629, 0.8174262693962373], [0.5019128177176975, 0.49808718228230253], [0.48214016345863575, 0.5178598365413641], [0.6021017219739855, 0.3978982780260145]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: -0.2180 - val_loss: -0.7744\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8147 - val_loss: -0.8916\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8909 - val_loss: -0.9045\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8987 - val_loss: -0.9056\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8993 - val_loss: -0.9059\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.8996 - val_loss: -0.9061\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.8998 - val_loss: -0.9064\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9000 - val_loss: -0.9066\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9002 - val_loss: -0.9067\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9004 - val_loss: -0.9069\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9007 - val_loss: -0.9071\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9010 - val_loss: -0.9073\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9013 - val_loss: -0.9077\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9018 - val_loss: -0.9081\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9023 - val_loss: -0.9087\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9031 - val_loss: -0.9094\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9040 - val_loss: -0.9104\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9054 - val_loss: -0.9117\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9070 - val_loss: -0.9134\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9095 - val_loss: -0.9156\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9123 - val_loss: -0.9178\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9154 - val_loss: -0.9193\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9173 - val_loss: -0.9206\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: -0.9189 - val_loss: -0.9215\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9200 - val_loss: -0.9219\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9209 - val_loss: -0.9223\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9214 - val_loss: -0.9230\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9222 - val_loss: -0.9236\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9226 - val_loss: -0.9237\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9227 - val_loss: -0.9222\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9202 - val_loss: -0.9178\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9203 - val_loss: -0.9220\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9209 - val_loss: -0.9234\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9220 - val_loss: -0.9234\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9227 - val_loss: -0.9230\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9224 - val_loss: -0.9212\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9225 - val_loss: -0.9213\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9220 - val_loss: -0.9237\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9240\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9239\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9241\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: -0.9237 - val_loss: -0.9240\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9237 - val_loss: -0.9237\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9234 - val_loss: -0.9239\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9236 - val_loss: -0.9241\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9232\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9235 - val_loss: -0.9238\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9233 - val_loss: -0.9238\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9221 - val_loss: -0.9224\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9222 - val_loss: -0.9234\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 805us/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "[[0.4327754452785336, 0.5672245547214664], [0.36287916217129157, 0.6371208378287084], [0.4486048591727056, 0.5513951408272943], [0.28447636390448555, 0.7155236360955144], [0.20587272408852475, 0.7941272759114752], [0.18529305330944335, 0.8147069466905568], [0.11209625504288959, 0.8879037449571103], [0.299459154874421, 0.700540845125579], [0.508332586136131, 0.4916674138638691], [0.15594527297868727, 0.8440547270213128], [0.2810089585692692, 0.7189910414307306], [0.717710180224655, 0.28228981977534506], [0.3731887546291116, 0.6268112453708885], [0.30110196393786515, 0.6988980360621349], [0.41603337592968065, 0.5839666240703194], [0.25790464748650394, 0.742095352513496], [0.3995544703770523, 0.6004455296229476], [0.24988070562733497, 0.7501192943726651], [0.4703510016468304, 0.5296489983531696], [0.3652731904108584, 0.6347268095891417], [0.0417571157111113, 0.9582428842888887], [0.07891474634091124, 0.9210852536590888], [0.19788638259386185, 0.8021136174061383], [0.40590008996406357, 0.5940999100359364], [0.1525988410398078, 0.8474011589601922], [0.19296699290462804, 0.807033007095372], [0.46800894025396667, 0.5319910597460333], [0.4711389667920022, 0.5288610332079978], [0.5550893472242487, 0.44491065277575126], [0.5782826761642554, 0.4217173238357446], [0.26755389396121154, 0.7324461060387883], [0.5039041305433813, 0.49609586945661865], [0.4660454790150248, 0.5339545209849752], [0.3066702020380849, 0.6933297979619151], [0.22017393587814227, 0.7798260641218577], [0.10560185825226703, 0.894398141747733], [0.07863483963164895, 0.921365160368351], [0.029599941888546775, 0.9704000581114534], [0.045404599488762507, 0.9545954005112375], [0.029345518740388182, 0.9706544812596118], [0.7170836069846349, 0.2829163930153651], [0.4486533480359576, 0.5513466519640424], [0.5318671978836123, 0.46813280211638775], [0.6141621407105133, 0.3858378592894867], [0.45322304645710454, 0.5467769535428953], [0.27629773969234916, 0.7237022603076508], [0.3470291878017287, 0.6529708121982712], [0.3227455494128435, 0.6772544505871564], [0.43897020721618896, 0.5610297927838112], [0.29804507553102494, 0.7019549244689749], [0.4347381579335108, 0.5652618420664892], [0.21002445553962995, 0.78997554446037], [0.26790565208790124, 0.7320943479120987], [0.1763269166858654, 0.8236730833141346], [0.5316412160978059, 0.4683587839021941], [0.35845447176330736, 0.6415455282366926], [0.4299752464299308, 0.5700247535700692], [0.27181754702331906, 0.7281824529766809], [0.5073930501292693, 0.4926069498707307], [0.33650832766183336, 0.6634916723381666]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7333333333333333%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: -0.1781 - val_loss: -0.7628\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8114 - val_loss: -0.8897\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.8932 - val_loss: -0.9029\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9013 - val_loss: -0.9040\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9019 - val_loss: -0.9044\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9022 - val_loss: -0.9047\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9025 - val_loss: -0.9050\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9028 - val_loss: -0.9054\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9033 - val_loss: -0.9058\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9037 - val_loss: -0.9062\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9044 - val_loss: -0.9065\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9051 - val_loss: -0.9069\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9061 - val_loss: -0.9076\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9073 - val_loss: -0.9085\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9087 - val_loss: -0.9098\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9109 - val_loss: -0.9118\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9137 - val_loss: -0.9139\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9165 - val_loss: -0.9157\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9190 - val_loss: -0.9171\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9209 - val_loss: -0.9182\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9224 - val_loss: -0.9191\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9233 - val_loss: -0.9201\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9242 - val_loss: -0.9208\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9250 - val_loss: -0.9194\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9239 - val_loss: -0.9208\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9252 - val_loss: -0.9214\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9256 - val_loss: -0.9217\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9254 - val_loss: -0.9215\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9259 - val_loss: -0.9215\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9259 - val_loss: -0.9218\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9218\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9266 - val_loss: -0.9200\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9200\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9245 - val_loss: -0.9203\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9254 - val_loss: -0.9218\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: -0.9258 - val_loss: -0.9199\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9248 - val_loss: -0.9194\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9241 - val_loss: -0.9216\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9257 - val_loss: -0.9197\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9244 - val_loss: -0.9205\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9255 - val_loss: -0.9207\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: -0.9256 - val_loss: -0.9213\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9256 - val_loss: -0.9187\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9232 - val_loss: -0.9218\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9248 - val_loss: -0.9208\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9240 - val_loss: -0.9208\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9259 - val_loss: -0.9194\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9251 - val_loss: -0.9169\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9224 - val_loss: -0.8981\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9085 - val_loss: -0.9037\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 903us/step\n",
      "[[0.27213714742193884, 0.727862852578061], [0.4500632690399876, 0.5499367309600124], [0.461796737369797, 0.538203262630203], [0.37180015958980084, 0.6281998404101992], [0.24505711173315792, 0.754942888266842], [0.22527545715740527, 0.7747245428425948], [0.23081799852908713, 0.769182001470913], [0.32208524066751243, 0.6779147593324875], [0.32167663402947266, 0.6783233659705274], [0.32662093188050934, 0.6733790681194907], [0.36927453045961883, 0.6307254695403813], [0.24992497103753353, 0.7500750289624666], [0.3611142887949892, 0.6388857112050108], [0.31436369252665686, 0.6856363074733431], [0.4063732479908702, 0.5936267520091298], [0.4108655965821523, 0.5891344034178478], [0.38071384167512784, 0.6192861583248723], [0.42686990427650157, 0.5731300957234985], [0.28043217688244715, 0.7195678231175529], [0.3962919623696809, 0.6037080376303192], [0.20458035145963366, 0.7954196485403662], [0.22509107811848733, 0.7749089218815127], [0.2976128931035015, 0.7023871068964984], [0.3784866587161398, 0.6215133412838603], [0.16416855529319466, 0.8358314447068051], [0.3442753108587333, 0.6557246891412667], [0.38205178941001927, 0.6179482105899807], [0.5379230593515383, 0.46207694064846183], [0.49074595438839785, 0.5092540456116021], [0.42222695445588654, 0.5777730455441135], [0.5662203936282738, 0.4337796063717263], [0.5359408765353888, 0.4640591234646113], [0.3879240400886359, 0.6120759599113641], [0.2449434676771831, 0.7550565323228167], [0.3339091220416496, 0.6660908779583505], [0.34021413145122, 0.6597858685487801], [0.2479275065172276, 0.7520724934827725], [0.2428686432275981, 0.7571313567724018], [0.3459232752221368, 0.6540767247778634], [0.19394469179487986, 0.8060553082051203], [0.44003995371189564, 0.5599600462881043], [0.6418609997961444, 0.3581390002038555], [0.25016655289374967, 0.7498334471062503], [0.4140702366846528, 0.5859297633153472], [0.21180057673508867, 0.7881994232649114], [0.2564863944630027, 0.7435136055369973], [0.23897235406096362, 0.7610276459390365], [0.265226253334374, 0.7347737466656262], [0.41084303850047654, 0.5891569614995233], [0.32002439250042186, 0.679975607499578], [0.30008516951234987, 0.6999148304876502], [0.0798306542733289, 0.9201693457266711], [0.11024035952725572, 0.8897596404727443], [0.04712376644776666, 0.9528762335522333], [0.056113564931002065, 0.9438864350689979], [0.6881596381365205, 0.31184036186347946], [0.47199135480235677, 0.5280086451976432], [0.2507730673081616, 0.7492269326918384], [0.25630688549395564, 0.7436931145060444], [0.6116782822600295, 0.3883217177399705]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7%\n",
      "-----------------------------------------\n",
      "(615, 1000)\n",
      "\n",
      "Autoencoder Created:\n",
      "Layers: [500, 250, 50]\n",
      "Input Length: 1000\n",
      "Compression: 50\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Loss: cosine_similarity\n",
      "\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: -0.1800 - val_loss: -0.7479\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.8102 - val_loss: -0.8785\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.8969 - val_loss: -0.8936\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9065 - val_loss: -0.8947\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9072 - val_loss: -0.8948\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9074 - val_loss: -0.8949\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9076 - val_loss: -0.8950\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9078 - val_loss: -0.8952\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9079 - val_loss: -0.8954\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9081 - val_loss: -0.8956\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9083 - val_loss: -0.8959\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9085 - val_loss: -0.8961\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9087 - val_loss: -0.8965\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: -0.9090 - val_loss: -0.8969\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9093 - val_loss: -0.8974\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9097 - val_loss: -0.8979\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9101 - val_loss: -0.8985\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9106 - val_loss: -0.8992\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9112 - val_loss: -0.9001\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9120 - val_loss: -0.9016\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9133 - val_loss: -0.9035\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9152 - val_loss: -0.9062\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9176 - val_loss: -0.9095\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9203 - val_loss: -0.9127\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9226 - val_loss: -0.9149\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: -0.9245 - val_loss: -0.9164\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9256 - val_loss: -0.9176\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: -0.9265 - val_loss: -0.9181\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9171\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9264 - val_loss: -0.9174\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9161\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9252 - val_loss: -0.9165\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9272 - val_loss: -0.9193\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9274 - val_loss: -0.9187\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9275 - val_loss: -0.9185\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9278 - val_loss: -0.9198\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9273 - val_loss: -0.9175\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9258 - val_loss: -0.9186\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9267 - val_loss: -0.9165\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9262 - val_loss: -0.9171\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9271 - val_loss: -0.9181\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9270 - val_loss: -0.9160\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: -0.9266 - val_loss: -0.9176\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9273 - val_loss: -0.9180\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9272 - val_loss: -0.9181\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9275 - val_loss: -0.9194\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -0.9282 - val_loss: -0.9194\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: -0.9285 - val_loss: -0.9194\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: -0.9284 - val_loss: -0.9194\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -0.9281 - val_loss: -0.9191\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 783us/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "[[0.27568774974071075, 0.7243122502592892], [0.13013856166985704, 0.869861438330143], [0.15377292499711145, 0.8462270750028884], [0.11661927066560226, 0.8833807293343976], [0.2169447062605829, 0.7830552937394171], [0.24092330062260411, 0.7590766993773959], [0.1532914269886661, 0.846708573011334], [0.47858186526330404, 0.521418134736696], [0.252314714240681, 0.7476852857593188], [0.39927466853494475, 0.6007253314650552], [0.6220577571717938, 0.37794224282820615], [0.6323048411410859, 0.36769515885891424], [0.8178242003756996, 0.1821757996243004], [0.5096345475030272, 0.49036545249697283], [0.39508532011490916, 0.6049146798850911], [0.2057510885709366, 0.7942489114290634], [0.6929720256744476, 0.3070279743255524], [0.3310000922692775, 0.6689999077307225], [0.36463132923374314, 0.6353686707662569], [0.4979255527071209, 0.5020744472928791], [0.3824987383294314, 0.6175012616705687], [0.39309825159791023, 0.6069017484020898], [0.1311832250422581, 0.8688167749577419], [0.6595675527634066, 0.34043244723659327], [0.7265505426193839, 0.2734494573806161], [0.465142802646437, 0.534857197353563], [0.3095887649991238, 0.6904112350008762], [0.5841238408023506, 0.4158761591976494], [0.5967625103848067, 0.40323748961519335], [0.5251677341516747, 0.4748322658483252], [0.14446406181358043, 0.8555359381864196], [0.15680093037872087, 0.8431990696212792], [0.19811047659978318, 0.8018895234002168], [0.11423026049996572, 0.8857697395000342], [0.08319260425740586, 0.9168073957425942], [0.16358816463694023, 0.8364118353630597], [0.41222357045308766, 0.5877764295469123], [0.15551502843778325, 0.8444849715622167], [0.3974574566813651, 0.6025425433186349], [0.22045458942306018, 0.7795454105769398], [0.3503457501292343, 0.6496542498707656], [0.6285933393401955, 0.3714066606598046], [0.3314395479211205, 0.6685604520788794], [0.6354099857009099, 0.3645900142990901], [0.6103252322323429, 0.38967476776765714], [0.4177205950521935, 0.5822794049478066], [0.2484299092797477, 0.7515700907202523], [0.32020960544209753, 0.6797903945579025], [0.4331504344381202, 0.5668495655618798], [0.24428077240124785, 0.7557192275987521], [0.12887379286722278, 0.8711262071327772], [0.007567298660228477, 0.9924327013397716], [0.007562175340299924, 0.9924378246597001], [0.009859408321429827, 0.9901405916785703], [0.0341611719339874, 0.9658388280660125], [0.36996069372641177, 0.6300393062735883], [0.3641326044388151, 0.6358673955611849], [0.26974001553657445, 0.7302599844634254], [0.4658768326846624, 0.5341231673153376], [0.742466517663378, 0.2575334823366219]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.8%\n",
      "-----------------------------------------\n",
      "[82.67, 68.0, 69.33, 74.67, 73.33, 81.67, 76.67, 80.0, 75.0, 66.67, 76.0, 74.67, 73.33, 74.67, 82.67, 75.0, 80.0, 81.67, 85.0, 68.33, 74.67, 70.67, 70.67, 77.33, 74.67, 71.67, 80.0, 73.33, 70.0, 80.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#all_corr = []\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def classification(training_set_x, testing_set_x, training_set_y, testing_set_y):\n",
    "    \n",
    "    train, y_train = separate_classes(training_set_x, training_set_y)\n",
    "    \n",
    "    n_train, n_test, n_ytrain, n_ytest = \\\n",
    "            train_test_split(train[1], y_train[1], test_size=.4, random_state=42)\n",
    "\n",
    "    loss = 'cosine_similarity'\n",
    "    activ='tanh'\n",
    "    opt='adam'\n",
    "\n",
    "    nodes = [500,250,50]\n",
    "\n",
    "    create_autoencoder(n_train, n_train, n_test, n_test, 'RN', loss, activ, opt, nodes = nodes, epochs=50)\n",
    "\n",
    "    encoder = pickle.load(open('RN_encoder', 'rb'))\n",
    "    decoder = pickle.load(open('RN_decoder', 'rb'))\n",
    "\n",
    "    enc = encoder.predict(testing_set_x)\n",
    "    dec = decoder.predict(enc)\n",
    "\n",
    "    enc_train = encoder.predict(training_set_x)\n",
    "    dec_train = decoder.predict(enc_train)\n",
    "    train_cl,test_cl = [],[]\n",
    "    y_train_new = []\n",
    "    y_test_new = []\n",
    "    for d in range(len(dec_train)):\n",
    "        corr_train = [pearsonr(dec_train[d][i:i+100],training_set_x[d][i:i+100])[0] for i in range(0,len(dec_train[d]),100)]\n",
    "        if np.isfinite(corr_train).all():\n",
    "            train_cl += [corr_train]\n",
    "            y_train_new += [training_set_y[d]]\n",
    "\n",
    "    for d in range(len(dec)):\n",
    "\n",
    "        corr = [pearsonr(dec[d][i:i+100],testing_set_x[d][i:i+100])[0] for i in range(0,len(dec[d]),100)]\n",
    "\n",
    "        if np.isfinite(corr).all():\n",
    "            test_cl += [corr]\n",
    "            y_test_new += [testing_set_y[d]]\n",
    "\n",
    "\n",
    "\n",
    "    names = [\"SVM\", \"RF\",\"NB\"]\n",
    "\n",
    "    classifiers = [SVC(gamma=2, C=1, probability=True),\n",
    "                   RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), GaussianNB()]\n",
    "    \n",
    "\n",
    "    _score = fus_classifier(classifiers, names, train_cl,\\\n",
    "                                  test_cl, np.array(y_train_new), np.array(y_test_new), show=False)\n",
    "    return _score\n",
    "\n",
    "all_score = []\n",
    "for fsx in range(len(FS_X_train)):\n",
    "    \n",
    "    signal_train = FS_X_train[fsx]\n",
    "    _ap_train = y_train[fsx]\n",
    "    signal_test = FS_X_test[fsx]\n",
    "    _ap_test = y_test[fsx]\n",
    "    print(signal_train.shape)\n",
    "    all_score += [classification(signal_train, signal_test, _ap_train, _ap_test)]\n",
    "    \n",
    "print(all_score)\n",
    "df = pd.DataFrame(all_score)\n",
    "df.to_csv (r'score_NB_bitalino.csv', index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    75.412\n",
      "dtype: float64\n",
      "0    4.871754\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.read_csv(r'score_NB_bitalino.csv', header=[0])\n",
    "print(table1.mean())\n",
    "print(table1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 736us/step\n",
      "20/20 [==============================] - 0s 771us/step\n",
      "[[0.273470965736019, 0.7265290342639812], [0.13920944320860903, 0.8607905567913909], [0.07870259838143319, 0.9212974016185669], [0.15755617963703802, 0.842443820362962], [0.2001417644275123, 0.7998582355724878], [0.2588069524309679, 0.7411930475690321], [0.20368063859454696, 0.7963193614054531], [0.4114689030688597, 0.5885310969311403], [0.20501163295851854, 0.7949883670414813], [0.28156834179133344, 0.7184316582086666], [0.569947946223693, 0.430052053776307], [0.5476772615001811, 0.4523227384998189], [0.6759844038648067, 0.3240155961351932], [0.5140673350335973, 0.4859326649664026], [0.3759339318825569, 0.6240660681174433], [0.21215072508897448, 0.7878492749110254], [0.5867859165851786, 0.41321408341482124], [0.15591603602228307, 0.844083963977717], [0.5077010216561431, 0.49229897834385694], [0.2983130091288124, 0.7016869908711877], [0.42053640386021357, 0.5794635961397864], [0.41030967480043473, 0.5896903251995651], [0.0959153407890516, 0.9040846592109483], [0.6418493279000373, 0.3581506720999627], [0.4779363945808707, 0.5220636054191292], [0.42247302959956107, 0.577526970400439], [0.2814157950073464, 0.7185842049926537], [0.5252280656375642, 0.47477193436243587], [0.5692809325429438, 0.43071906745705624], [0.49391269071291655, 0.5060873092870835], [0.16117223045205373, 0.8388277695479465], [0.18590992534670028, 0.8140900746532997], [0.29489545000766754, 0.7051045499923324], [0.1890290277814141, 0.8109709722185858], [0.10019359662412992, 0.8998064033758699], [0.30989249829900073, 0.6901075017009992], [0.4522961516080351, 0.5477038483919648], [0.13920557633215605, 0.8607944236678439], [0.32329734900987256, 0.6767026509901276], [0.21010952607032415, 0.7898904739296758], [0.39960044303408404, 0.6003995569659158], [0.49346845303554915, 0.5065315469644509], [0.4318949267102774, 0.5681050732897225], [0.49882594848127115, 0.501174051518729], [0.5693983155161813, 0.43060168448381875], [0.3495814525526526, 0.6504185474473475], [0.30690181455505217, 0.6930981854449478], [0.3092676188106006, 0.6907323811893994], [0.4518431445658219, 0.5481568554341779], [0.25987146946081574, 0.7401285305391841], [0.17756817166157343, 0.8224318283384267], [0.0483606046531495, 0.9516393953468505], [0.047890572015989195, 0.9521094279840107], [0.05876655744206164, 0.9412334425579383], [0.024671646431499866, 0.9753283535685], [0.4059210656755496, 0.5940789343244504], [0.2999444193615233, 0.7000555806384767], [0.30935627667990273, 0.6906437233200972], [0.5257452562699406, 0.4742547437300595], [0.8055052669933437, 0.19449473300665635]]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "['SVM', 'RF', 'NB'] --- Accuracy: 0.7666666666666667%\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, y_train = separate_classes(signal_train, _ap_train)\n",
    "\n",
    "n_train, n_test, n_ytrain, n_ytest = \\\n",
    "        train_test_split(train[1], y_train[1], test_size=.4, random_state=42)\n",
    "\n",
    "\n",
    "encoder = pickle.load(open('RN_encoder', 'rb'))\n",
    "decoder = pickle.load(open('RN_decoder', 'rb'))\n",
    "\n",
    "enc = encoder.predict(signal_test)\n",
    "dec = decoder.predict(enc)\n",
    "\n",
    "enc_train = encoder.predict(signal_train)\n",
    "dec_train = decoder.predict(enc_train)\n",
    "train_cl,test_cl = [],[]\n",
    "y_train_new = []\n",
    "y_test_new = []\n",
    "for d in range(len(dec_train)):\n",
    "    corr_train = [pearsonr(dec_train[d][i:i+100],signal_train[d][i:i+100])[0] for i in range(0,len(dec_train[d]),100)]\n",
    "    if np.isfinite(corr_train).all():\n",
    "        train_cl += [corr_train]\n",
    "        y_train_new += [_ap_train[d]]\n",
    "\n",
    "for d in range(len(dec)):\n",
    "\n",
    "    corr = [pearsonr(dec[d][i:i+100],signal_test[d][i:i+100])[0] for i in range(0,len(dec[d]),100)]\n",
    "\n",
    "    if np.isfinite(corr).all():\n",
    "        test_cl += [corr]\n",
    "        y_test_new += [_ap_test[d]]\n",
    "\n",
    "\n",
    "ns = [\"SVM\", \"RF\", \"NB\"]\n",
    "\n",
    "cl = [SVC(gamma=2, C=1, probability=True),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), GaussianNB()]\n",
    "\n",
    "\n",
    "all_scores = []\n",
    "    \n",
    "    # Train the classifier\n",
    "y_pred = []\n",
    "\n",
    "train_cl,test_cl, np.array(y_train_new), np.array(y_test_new)\n",
    "\n",
    "cl[0].fit(train_cl, np.array(y_train_new).ravel())\n",
    "cl[1].fit(train_cl, np.array(y_train_new).ravel())\n",
    "cl[2].fit(train_cl, np.array(y_train_new).ravel())\n",
    "\n",
    "proba1 = cl[0].predict_proba(test_cl)\n",
    "proba2 = cl[1].predict_proba(test_cl)\n",
    "proba3 = cl[1].predict_proba(test_cl)\n",
    "\n",
    "#prob = [proba1[pb] if np.argmax([proba1[pb], proba2[pb]]) in [0,1] else proba2[pb] for pb in range(len(proba1))]\n",
    "prob= [[np.mean([proba1[i,0],proba2[i,0],proba3[i,0]]),np.mean([proba1[i,1],proba2[i,1],proba3[i,1]])] for i in range(len(proba1))]\n",
    "\n",
    "\n",
    "print(prob)\n",
    "y_pred = [np.argmax(prob[i]) for i in range(len(prob))]\n",
    "\n",
    "y_test = [1 if yt == 'N' else 0 for yt in y_test_new]\n",
    "print(y_test, y_pred)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "#print(c.predict_proba(test))\n",
    "# Get the classification accuracy\n",
    "print(str(ns) + \" --- Accuracy: \" + str(score) + '%')\n",
    "print('-----------------------------------------')\n",
    "class_names = np.array(['Apnea', 'Normal'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
