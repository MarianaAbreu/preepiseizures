{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to plot ACC Seizure Detection Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is focused solely on FBTC seizures.\n",
    "\n",
    "A patient-specific approach will be tested\n",
    "\n",
    "SET 2\n",
    "- Training: BLIW_1, BLIW_2, YIVL_0, YIVL_1, AGGA_0, AGGA_1, AGGA_2, YWJN_5, YWJN_6 \n",
    "- Testing: VNVW_1, WOSQ_2, AGGA_3, YIVL_2,  BLIW_3, YWJN_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "from datetime import datetime\n",
    "\n",
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "from fast_ml.feature_selection import get_constant_features\n",
    "\n",
    "from preepiseizures.src import Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87810, 1559)\n",
      "(87810, 1557)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('./data/features/all_patients_acc_features.parquet')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# remove columns with nans\n",
    "data = data.dropna(axis=1)\n",
    "print(data.shape)\n",
    "data['patient'] = data['patient_seizure'].apply(lambda x: x.split('_')[0])\n",
    "data['patient'].unique()\n",
    "\n",
    "training_set_keys = ['BLIW_0', 'BLIW_1', 'BLIW_2', 'YIVL_0', 'YIVL_1', 'AGGA_0', 'AGGA_1', 'AGGA_2', 'YWJN_4', 'YWJN_5', 'YWJN_6'] \n",
    "testing_set_keys = ['VNVW_0', 'VNVW_1', 'WOSQ_2', 'AGGA_3', 'YIVL_2',  'BLIW_3', 'YWJN_7']\n",
    "all_training_set = data[data['patient_seizure'].isin(training_set_keys)].copy()\n",
    "all_testing_set = data[data['patient_seizure'].isin(testing_set_keys)].copy()\n",
    "\n",
    "features_cols = all_training_set.drop(columns=['patient_seizure', 'patient', 'timestamp', 'y']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Select patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3264, 1558) (2013, 1558)\n",
      "Number of features excluded:  58\n",
      "Dropping 1214 features from 1496.\n",
      "New shape:  (2821, 286)\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "patient = 'AGGA'\n",
    "training_set = all_training_set[all_training_set['patient'] == patient].copy()\n",
    "testing_set = all_testing_set[all_testing_set['patient'] == patient].copy()\n",
    "\n",
    "train_seizures = training_set['patient_seizure'].unique()\n",
    "test_seizures = testing_set['patient_seizure'].unique()\n",
    "print(training_set.shape, testing_set.shape)\n",
    "\n",
    "patient_ = Patient.patient_class(patient)\n",
    "patient_.get_seizure_annotations()\n",
    "\n",
    "seiz_surrounding_index = []\n",
    "\n",
    "for seizure in patient_.seizure_table.index:\n",
    "\n",
    "    onset = patient_.seizure_table.loc[seizure]['Timestamp']\n",
    "    # preictal period is 10 minutes before seizure\n",
    "    start = onset - pd.Timedelta(minutes=10)\n",
    "    try:\n",
    "        end_time = datetime.combine(onset.date(), patient_.seizure_table.loc[seizure, 'Fim'])\n",
    "    except:\n",
    "        end_time = onset + pd.Timedelta(minutes=2)\n",
    "    seiz_surrounding_index += [training_set.loc[training_set['timestamp'].between(start, onset - pd.Timedelta(seconds=30))].index]\n",
    "    posictal_0 = end_time\n",
    "    posictal_1 = onset + pd.Timedelta(minutes=10)\n",
    "    seiz_surrounding_index += [training_set.loc[training_set['timestamp'].between(posictal_0, posictal_1)].index]\n",
    "    \n",
    "seiz_surrounding_index = np.hstack(seiz_surrounding_index)      \n",
    "\n",
    "training_set.drop(seiz_surrounding_index, inplace=True)\n",
    "\n",
    "constant_features = get_constant_features(training_set[features_cols])\n",
    "# print(constant_features)\n",
    "exclude_cols = constant_features.Var\n",
    "training_set.drop(columns=exclude_cols, inplace=True)\n",
    "print('Number of features excluded: ', len(exclude_cols))\n",
    "features_cols = training_set.drop(columns=['patient_seizure', 'patient', 'timestamp', 'y']).columns\n",
    "\n",
    "corr_matrix = training_set[features_cols].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(f'Dropping {len(to_drop)} features from {corr_matrix.shape[1]}.')\n",
    "\n",
    "# Drop features \n",
    "#if to_drop[0] in training_set.columns:\n",
    "#    training_set.drop(to_drop, axis=1, inplace=True)\n",
    "new_training_set = training_set.drop(columns=to_drop)\n",
    "new_testing_set = testing_set.drop(columns=to_drop)\n",
    "features_cols = new_training_set.drop(columns=['patient_seizure', 'timestamp', 'y', 'patient']).columns\n",
    "\n",
    "print('New shape: ', new_training_set.shape)\n",
    "print(len(features_cols))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(new_training_set[features_cols])\n",
    "new_training_set[features_cols] = scaler.transform(new_training_set[features_cols])\n",
    "new_testing_set[features_cols] = scaler.transform(new_testing_set[features_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected:  6\n",
      "(2086, 6) (2086,)\n",
      "Class 0:  1043\n",
      "Class 1:  1043\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_ = new_training_set[features_cols].copy()\n",
    "y_train_ = new_training_set['y'].copy()\n",
    "X_test_ = new_testing_set[features_cols].copy()\n",
    "y_test_ = new_testing_set['y'].copy()\n",
    "\n",
    "\n",
    "percentile = 2\n",
    "selector_anova = SelectPercentile(score_func=f_classif, percentile=percentile)\n",
    "X_train_ANOVA = selector_anova.fit_transform(X_train_, y_train_)\n",
    "X_test_ANOVA = selector_anova.transform(X_test_)\n",
    "\n",
    "\n",
    "feature_index = selector_anova.get_support(indices=True)\n",
    "feature_names = X_train_.columns[feature_index]\n",
    "\n",
    "# Convert selected features to DataFrame\n",
    "features_anova_train1 = pd.DataFrame(X_train_ANOVA, columns=feature_names, index=X_train_.index)\n",
    "features_anova_test1 = pd.DataFrame(X_test_ANOVA, columns=feature_names, index=X_test_.index)\n",
    "\n",
    "print('Number of features selected: ', len(feature_names))\n",
    "\n",
    "training_set_keys = new_training_set['patient_seizure'].unique()\n",
    "\n",
    "validation_set_keys = [training_set_keys[-1]]\n",
    "training_set_keys_subset = training_set_keys[:-1]\n",
    "\n",
    "X_train = features_anova_train1.loc[new_training_set.loc[new_training_set['patient_seizure'].isin(training_set_keys_subset)].index]\n",
    "y_train = y_train_.loc[new_training_set.loc[new_training_set['patient_seizure'].isin(training_set_keys_subset)].index]\n",
    "X_val = features_anova_train1.loc[new_training_set.loc[new_training_set['patient_seizure'].isin(validation_set_keys)].index]\n",
    "y_val = y_train_.loc[new_training_set.loc[new_training_set['patient_seizure'].isin(validation_set_keys)].index]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_ANOVA, y_train_, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE for oversampling and NearMiss for undersampling\n",
    "oversampler = SMOTE(sampling_strategy=0.5)  # Adjust the sampling strategy as needed\n",
    "undersampler = NearMiss()\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_resampled, y_train_resampled)\n",
    "print(X_train_resampled.shape, y_train_resampled.shape)\n",
    "# print number of samples in each class\n",
    "print('Class 0: ', len(y_train_resampled[y_train_resampled == 0]))\n",
    "print('Class 1: ', len(y_train_resampled[y_train_resampled == 1]))\n",
    "\n",
    "\n",
    "# Define a list of classifiers to test\n",
    "classifiers = [\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_layer(df, life):\n",
    "    \"\"\"\n",
    "    Decision layer to detect a seizure\n",
    "    :param df: dataframe with y_pred column, timestamp column and index\n",
    "    :return: index of seizure\n",
    "    \"\"\"\n",
    "    consecutive_preds = 0\n",
    "    seizure_counter_dict = {}\n",
    "    # all index of N consecutive 1s\n",
    "    # add a median filter to smooth the prediction\n",
    "    i = 0\n",
    "    alarm = False\n",
    "    \n",
    "    while i < len(df):\n",
    "        # in an alarm is raised\n",
    "        if (consecutive_preds >= life and not alarm):\n",
    "            # raise an alarm\n",
    "            seizure_counter_dict[df['time'].iloc[i]] = i\n",
    "            alarm = True\n",
    "            # wait for \n",
    "            # print('Seizure detected at index: ', i)\n",
    "        else:\n",
    "            if df['y_pred'].iloc[i] == 1:\n",
    "                consecutive_preds += 1\n",
    "            if df['y_pred'].iloc[i] == 0:\n",
    "                consecutive_preds = 0\n",
    "                alarm = False\n",
    "        i += 1\n",
    "    # after a consec_index wait for 2 minutes before the next prediction\n",
    "    return seizure_counter_dict\n",
    "\n",
    "def eval_alarms(preds, seizure):\n",
    "    \"\"\"\n",
    "    Evaluate the alarms\n",
    "    :param preds: list of predictions\n",
    "    :param seizure: seizure dataframe\n",
    "    \"\"\"\n",
    "    true_alarm, false_alarm = 0, 0\n",
    "    if type(preds) == dict:\n",
    "        preds = list(preds.keys())\n",
    "    \n",
    "    if seizure is None:\n",
    "        # every alarm is a false alarm\n",
    "        return 0, len(preds)\n",
    "    \n",
    "    seizure_range_start = seizure['Timestamp'] - pd.Timedelta(seconds=30)\n",
    "    seizure_range_end = seizure['Timestamp'] + pd.Timedelta(seconds=180)\n",
    "\n",
    "\n",
    "    for alarm in preds:\n",
    "        if (seizure_range_start <= alarm) and (alarm <= seizure_range_end):\n",
    "            print('Seizure detected at: ', alarm - seizure['Timestamp'])\n",
    "            true_alarm += 1\n",
    "        else:\n",
    "            false_alarm += 1\n",
    "    \n",
    "    return true_alarm, false_alarm\n",
    "\n",
    "\n",
    "def eval_models(classifiers, X_train_resampled, y_train_resampled, X_val, y_val, new_training_set, new_testing_set, patient_):\n",
    "    \"\"\"\n",
    "    Evaluate the model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train and evaluate each classifier\n",
    "    for name, classifier in classifiers:\n",
    "        classifier.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = classifier.predict(X_val)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        # Print classification report and other metrics\n",
    "        print(f\"Classifier: {name} | Recall: {np.round(100*recall, 2)} | Accuracy: {np.round(100*accuracy, 2)} | Precision: {np.round(100*precision, 2)} | F1-score: {np.round(100*f1, 2)}\")\n",
    "\n",
    "        #EVENT BASED ANALYSIS\n",
    "        y_pred = classifier.predict(X_val)\n",
    "        y_pred_df = pd.DataFrame(y_pred, columns=['y_pred'], index=y_val.index)\n",
    "        y_pred_df['time'] = new_training_set.loc[y_pred_df.index, 'timestamp']\n",
    "        y_pred_df.sort_index(inplace=True)\n",
    "        # median filter to smooth the predictions\n",
    "\n",
    "        if precision < 0.1:\n",
    "            median = 10\n",
    "        else:\n",
    "            median = 10\n",
    "        y_pred_df['y_pred'] = y_pred_df['y_pred'].rolling(median, center=True).median()\n",
    "\n",
    "        val_alarms = decision_layer(y_pred_df, life=10)\n",
    "\n",
    "        val_seizure_idx = int(validation_set_keys[0].split('_')[-1])\n",
    "        val_seizure = patient_.seizure_table.loc[val_seizure_idx]\n",
    "        tp, fp = eval_alarms(val_alarms, val_seizure)\n",
    "        val_time = (y_pred_df['time'].iloc[-1] - y_pred_df['time'].iloc[0]).total_seconds()/3600\n",
    "        fp_rate = np.round(fp/val_time,2)\n",
    "        print(f'VAL SD: {tp}/1 | VAL FAR: {fp_rate}/h')\n",
    "\n",
    "        #TESTING SET\n",
    "        y_pred_test = classifier.predict(features_anova_test1)\n",
    "\n",
    "        y_pred_df_test = pd.DataFrame(y_pred_test, columns=['y_pred'], index=new_testing_set.index)\n",
    "        y_pred_df_test['time'] = new_testing_set['timestamp']\n",
    "\n",
    "        y_pred_df_test['y_pred'] = y_pred_df_test['y_pred'].rolling(median, center=True).median()\n",
    "\n",
    "\n",
    "        test_alarms = decision_layer(y_pred_df_test, life=10)\n",
    "        \n",
    "        test_seizures = new_testing_set['patient_seizure'].unique()\n",
    "        if len(test_seizures) > 1:\n",
    "            print('deal with multiple seizures')\n",
    "        else:\n",
    "            test_seizure_idx = int(test_seizures[0].split('_')[-1])\n",
    "        test_seizure = patient_.seizure_table.loc[test_seizure_idx]\n",
    "        if new_testing_set['y'].sum() == 0:\n",
    "            print('No seizure in testing set')\n",
    "            test_seizure = None\n",
    "        if y_val.sum() == 0:\n",
    "            print('No seizure in validation set')\n",
    "\n",
    "        tp, fp = eval_alarms(test_alarms, test_seizure)\n",
    "        \n",
    "        test_time = (y_pred_df_test['time'].iloc[-1] - y_pred_df_test['time'].iloc[0]).total_seconds()/3600\n",
    "        \n",
    "        fp_rate = np.round(fp/test_time,2)\n",
    "\n",
    "\n",
    "        print(f'TEST SD: {tp}/{len(test_seizures)} | TEST FAR: {fp_rate}/h')\n",
    "        print('\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest | Recall: 2.5 | Accuracy: 93.17 | Precision: 9.09 | F1-score: 3.92\n",
      "VAL SD: 0/1 | VAL FAR: 0.0/h\n",
      "TEST SD: 0/1 | TEST FAR: 0.0/h\n",
      "\n",
      "\n",
      "Classifier: SVM | Recall: 10.0 | Accuracy: 80.47 | Precision: 3.7 | F1-score: 5.41\n",
      "VAL SD: 0/1 | VAL FAR: 0.0/h\n",
      "TEST SD: 0/1 | TEST FAR: 0.34/h\n",
      "\n",
      "\n",
      "Classifier: Decision Tree | Recall: 2.5 | Accuracy: 90.1 | Precision: 3.03 | F1-score: 2.74\n",
      "VAL SD: 0/1 | VAL FAR: 0.0/h\n",
      "TEST SD: 0/1 | TEST FAR: 0.67/h\n",
      "\n",
      "\n",
      "Classifier: Logistic Regression | Recall: 60.0 | Accuracy: 66.25 | Precision: 9.6 | F1-score: 16.55\n",
      "VAL SD: 0/1 | VAL FAR: 3.23/h\n",
      "TEST SD: 0/1 | TEST FAR: 2.02/h\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_models(classifiers, X_train_resampled, y_train_resampled, X_val, y_val, new_training_set, new_testing_set, patient_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AGGA_3'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_testing_set['patient_seizure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
